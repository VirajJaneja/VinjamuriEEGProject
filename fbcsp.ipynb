{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Bank Common Spatial Pattern\n",
    "Attempt at implementing filter-bank common spatial filter (FBCSP) on BCI Competition IV 2a Dataset\n",
    "  \n",
    "**References:**   \n",
    "\n",
    "[1] Kai Keng Ang, Zheng Yang Chin, Haihong Zhang and Cuntai Guan, \"Filter Bank Common Spatial Pattern (FBCSP) in Brain-Computer Interface,\" 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence), Hong Kong, 2008, pp. 2390-2397, doi: 10.1109/IJCNN.2008.4634130.    \n",
    "[2] Ang, K. K., Chin, Z. Y., Wang, C., Guan, C., & Zhang, H. (2012). Filter Bank Common Spatial Pattern Algorithm on BCI Competition IV Datasets 2a and 2b. Frontiers in Neuroscience, 6. doi: 10.3389/fnins.2012.00039"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI Competition IV Dataset 2a (.npz data)\n",
    "Information Given in Documentation\n",
    "\n",
    "From the documentation it is known that:\n",
    "* 25 electrodes are used, first 22 are EEG, last 3 are EOG\n",
    "* Sampling frequency (fs) is 250Hz\n",
    "* 9 subjects\n",
    "* 9 run (run 1-3 are for eye movement, run 4-9 is MI)  \n",
    "  \n",
    "\n",
    "**-- Time Duration--**  \n",
    "1 trials                          = 7-8s  \n",
    "1 run              = 48 trials    = 336-384s  \n",
    "1 session = 6 runs = 288 trials   = 2016-2304s\n",
    "\n",
    "About the recording of eye movement\n",
    "* run 1 => 2 mins with eyes open\n",
    "* run 2 => 1 min with eyes closed\n",
    "* run 3 => 1 min with eye movements\n",
    "\n",
    "![timing-scheme-paradigm.png](./img/timing-scheme-paradigm.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nathan Dayie Documentation\n",
    "\n",
    "Last Updated: 4/2/2025\n",
    "\n",
    "The original notebook only classified the training dataset into the left hand and right hand classes. It did so by splitting the training dataset (denoted as AOXT.npz files) 80/20, 80% used to train a classic ML model and 20% used to test the model. Eventually, we want to use 100% of the training dataset to train a deep learning model and see if it can better classify this dataset than the classical models. This final goal will be approached in steps, step 0 of which has already been completed by working through this original notebook.\n",
    "\n",
    "#### Step 0 (complete as of 2/11/25) - Apply classical ML model to classify BCI Comp IV Dataset 2a (training data) into left hand and right hand classes.\n",
    "\n",
    "##### Modifications to notebook:\n",
    "- the original notebook only looked at subject's 1-3, but I modified it to classify all 9 subjects\n",
    "- this mostly just meant adjusting for loops that went in range(1,4) to range(1,ns) where ns = 10, 1 more than the number of subjects there were in the data set\n",
    "\n",
    "#### Step 1 (started 2/12/25) - Apply classical ML model to classify BCI Comp IV Dataset 2a (training data) into left hand, right hand, both feet, and tongue classes.\n",
    "\n",
    "##### Modifications to notebook:\n",
    "- added code to account for both feet (class 3) and tongue (class 4) classes\n",
    "\n",
    "#### Step 2 (started 3/26/2025) - Train classical ML model on 100% of BCI Comp training dataset and test on BCI Comp evaluation dataset\n",
    "\n",
    "##### Modifications to notebook:\n",
    "- added code to add a dictionary for the evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the data\n",
    "\n",
    "# Number of subject, n + 1 for iteration purpose (there are 9 subjects)\n",
    "ns = 10\n",
    "\n",
    "# Creating dict to store original data and modified data\n",
    "ori_data = dict() # ori_data will serve as initial loaded data that will remain unchanged\n",
    "mod_data = dict() # mod_data will contain modified original data\n",
    "\n",
    "# Step 2 Modification\n",
    "eval_data = dict() # eval_data will contain the original evaluation data\n",
    "mod_eval_data = dict() # mod_eval_data will contain modified evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count subject\n",
    "def subject_counter(i):\n",
    "    return 'subject0{}'.format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the notebook locally..\n"
     ]
    }
   ],
   "source": [
    "# Path manipulation if running in dev container\n",
    "if os.getcwd() == '/':\n",
    "    print(\"Running the notebook it inside dev container..\")\n",
    "    base_dir = os.environ[\"DOCKER_WORKDIR\"]\n",
    "else:\n",
    "    print(\"Running the notebook locally..\")\n",
    "    base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[subject01] Raw train EEG shape before filtering: (672528, 25)\n",
      "[subject01] Raw eval EEG shape before filtering: (687000, 25)\n",
      "[subject02] Raw train EEG shape before filtering: (677169, 25)\n",
      "[subject02] Raw eval EEG shape before filtering: (662666, 25)\n",
      "[subject03] Raw train EEG shape before filtering: (660530, 25)\n",
      "[subject03] Raw eval EEG shape before filtering: (648775, 25)\n",
      "[subject04] Raw train EEG shape before filtering: (600915, 25)\n",
      "[subject04] Raw eval EEG shape before filtering: (660047, 25)\n",
      "[subject05] Raw train EEG shape before filtering: (686120, 25)\n",
      "[subject05] Raw eval EEG shape before filtering: (679863, 25)\n",
      "[subject06] Raw train EEG shape before filtering: (678980, 25)\n",
      "[subject06] Raw eval EEG shape before filtering: (666373, 25)\n",
      "[subject07] Raw train EEG shape before filtering: (681071, 25)\n",
      "[subject07] Raw eval EEG shape before filtering: (673135, 25)\n",
      "[subject08] Raw train EEG shape before filtering: (675270, 25)\n",
      "[subject08] Raw eval EEG shape before filtering: (687792, 25)\n",
      "[subject09] Raw train EEG shape before filtering: (673328, 25)\n",
      "[subject09] Raw eval EEG shape before filtering: (675098, 25)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data of all subjects\n",
    "\n",
    "# Iter over all data path then store them in sub0X variable\n",
    "for i in range(1, ns):\n",
    "    data_path = os.path.join('A{:02d}T.npz'.format(i))\n",
    "    eval_data_path = os.path.join('A{:02d}E.npz'.format(i))\n",
    "    subject = 'subject{:02d}'.format(i)\n",
    "    \n",
    "    # Load EEG data from datapath and store into subj0X variable then store into data dictionary\n",
    "    ori_data[subject] = np.load(data_path)\n",
    "    print(f\"[{subject}] Raw train EEG shape before filtering:\", ori_data[subject]['s'].shape)\n",
    "    eval_data[subject] = np.load(eval_data_path) # Step 2 modification\n",
    "    # Add this after loading\n",
    "    print(f\"[{subject}] Raw eval EEG shape before filtering:\", eval_data[subject]['s'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.lib.npyio.NpzFile'>\n",
      "['s', 'etyp', 'epos', 'edur', 'artifacts']\n"
     ]
    }
   ],
   "source": [
    "# Peek into ori_data type and its keys \n",
    "print(type(ori_data['subject01']))\n",
    "# print(type(ori_data['subject01']['s']))\n",
    "print(ori_data['subject01'].files) # can replace 01 with 01-09 for subject0X key, and will get same output\n",
    "# the type of each value behind each key ['s', 'etyp', 'epos', 'edur', 'artifacts'] is a numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peak at data inside of ori_data['subject01']['artifacts'] using ravel\n",
    "# numpy.ndarray.ravel() flattens an m x n array into a 1 x mn array and displays it\n",
    "ori_data['subject01']['artifacts'].ravel()[20:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation regarding contents of the keys inside each subject data:\n",
    "* **s**: 's' contains continuous time-series recorded EEG signals are, shape of M x N array. Size may vary between subjects but N is fixed to 25, indicates 25 electrodes with 22 first EEG and 3 last EOG\n",
    "* **etype**: 'etyp' stands for event type which indicate event occurence, event code will be describe in subsequent table\n",
    "* **epos**: 'epos' stands for event position, denoting corresponding event begins at n-th sample at **'s'**\n",
    "* **edur**: 'edur' stands for event duration, denoting duration of corresponding event\n",
    "* **artifacts**: size of 288 x 1, 288 comes form 6 x 48, 6 runs where @run has 48 trials, @class has 12 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_data will contain original data that is the raw file\n",
    "# mod_data will contain modified original data\n",
    "\n",
    "# Initialize 'subject0x' dict inside mod_data\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    mod_data[subj] = {}\n",
    "    mod_eval_data[subj] = {} # Step 2 Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\tElectrodes\n",
      "subject01\t(672528, 25)\n",
      "subject01\t(687000, 25)\n",
      "subject02\t(677169, 25)\n",
      "subject02\t(662666, 25)\n",
      "subject03\t(660530, 25)\n",
      "subject03\t(648775, 25)\n",
      "subject04\t(600915, 25)\n",
      "subject04\t(660047, 25)\n",
      "subject05\t(686120, 25)\n",
      "subject05\t(679863, 25)\n",
      "subject06\t(678980, 25)\n",
      "subject06\t(666373, 25)\n",
      "subject07\t(681071, 25)\n",
      "subject07\t(673135, 25)\n",
      "subject08\t(675270, 25)\n",
      "subject08\t(687792, 25)\n",
      "subject09\t(673328, 25)\n",
      "subject09\t(675098, 25)\n"
     ]
    }
   ],
   "source": [
    "# Peek into different shape of recorded data/'s' between subjects\n",
    "print('Sample\\tElectrodes')\n",
    "for i in range(1, ns):\n",
    "    subj_temp = subject_counter(i)\n",
    "    print(f\"{subj_temp}\\t{ori_data[subj_temp]['s'].shape}\")\n",
    "    print(f\"{subj_temp}\\t{eval_data[subj_temp]['s'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract the sample data from ori_data into mod_data\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    mod_data[subj]['raw_EEG'] = ori_data[subj]['s']\n",
    "    mod_eval_data[subj]['raw_EEG'] = eval_data[subj]['s'] # Step 2 Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing sample_data inside subject01\n",
    "# You can see that it has 25 electrodes stored in columns\n",
    "# pd.DataFrame(mod_eval_data['subject01']['raw_EEG']).head() # Step 2 Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing last three EOG electrode using np.delete, store data as EEG_only to each subject dict\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    mod_data[subj]['raw_EEG'] = np.delete(mod_data[subj]['raw_EEG'], np.s_[22:], 1)\n",
    "    mod_eval_data[subj]['raw_EEG'] = np.delete(mod_eval_data[subj]['raw_EEG'], np.s_[22:], 1) # Step 2 Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass Filtering\n",
    "The first stage employing a filter bank is to decompose EEG into multiple frequency pass band, using causal Chebysev Type II filter/ Butterworth Filter.  \n",
    "A total of 9 band-pass filters are used, namely, 4-8, 8-12, ... 36-40 Hz  \n",
    "These frequency ranges are used because they yielf a stable frequency response and cover range of 4-40 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band pass filter with butterworth filter\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import freqz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def butter_bandpass_filter(signal, lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut/nyq\n",
    "    high = highcut/nyq\n",
    "    b,a = butter(order, [low, high], btype='band')\n",
    "    y = lfilter(b, a, signal, axis=-1)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "Create arbitrary signal and using butterworth signal as band-pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INPUT\n",
    "# # sampling frequency\n",
    "# fs = 500\n",
    "\n",
    "# # time\n",
    "# t = np.arange(0, 5, 1/fs)\n",
    "\n",
    "# # Three signals with various freq\n",
    "# x1 = np.sin(2 * np.pi * 6 * t)\n",
    "# x2 = np.sin(2 * np.pi * 7 * t)\n",
    "# x3 = np.sin(2 * np.pi * 50 * t)\n",
    "# x = x1 + x2 + x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot input\n",
    "# plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.clf()\n",
    "# plt.plot(t, x)\n",
    "# plt.xlabel('time (seconds)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OUTPUT\n",
    "# lowcut = 4\n",
    "# highcut = 8\n",
    "# y= butter_bandpass_filter(x, lowcut, highcut, fs, order=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot output\n",
    "# plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.clf()\n",
    "# plt.plot(t, y, label='Filtered signal (%g Hz)' %fs)\n",
    "# plt.xlabel('time (seconds)')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OUTPUT\n",
    "# lowcut = 36\n",
    "# highcut = 40\n",
    "# y= butter_bandpass_filter(x, lowcut, highcut, fs, order=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot output\n",
    "# plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.clf()\n",
    "# plt.plot(t, y, label='Filtered signal (%g Hz)' %fs)\n",
    "# plt.xlabel('time (seconds)')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering EEG signal with Butterworth Band-pass\n",
    "Following the steps mentioned in [1], there will be 8 band-pass filter with bandwidth of:\n",
    "1. 4-8Hz\n",
    "2. 8-12Hz\n",
    "3. 12-16Hz\n",
    "4. 16-20Hz\n",
    "5. 20-24Hz\n",
    "6. 24-28Hz\n",
    "7. 28-32Hz\n",
    "8. 32-36Hz\n",
    "9. 36-40Hz\n",
    "\n",
    "*Note*   \n",
    "Apply filter to the time-series axis, thus set 'raw_EEG' inside each subject to shape of N x T (i.e. electrodes x samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: subject01\t(22, 672528)\n",
      "Eval: subject01\t(22, 687000)\n",
      "Test: subject02\t(22, 677169)\n",
      "Eval: subject02\t(22, 662666)\n",
      "Test: subject03\t(22, 660530)\n",
      "Eval: subject03\t(22, 648775)\n",
      "Test: subject04\t(22, 600915)\n",
      "Eval: subject04\t(22, 660047)\n",
      "Test: subject05\t(22, 686120)\n",
      "Eval: subject05\t(22, 679863)\n",
      "Test: subject06\t(22, 678980)\n",
      "Eval: subject06\t(22, 666373)\n",
      "Test: subject07\t(22, 681071)\n",
      "Eval: subject07\t(22, 673135)\n",
      "Test: subject08\t(22, 675270)\n",
      "Eval: subject08\t(22, 687792)\n",
      "Test: subject09\t(22, 673328)\n",
      "Eval: subject09\t(22, 675098)\n"
     ]
    }
   ],
   "source": [
    "# Transpose all 'raw_EEG' data\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    while mod_data[subj]['raw_EEG'].shape[0] != 22:\n",
    "        mod_data[subj]['raw_EEG'] = mod_data[subj]['raw_EEG'].T\n",
    "        mod_eval_data[subj]['raw_EEG'] = mod_eval_data[subj]['raw_EEG'].T # Step 2 Modification\n",
    "    \n",
    "    print(f\"Test: {subj}\\t{mod_data[subj]['raw_EEG'].shape}\")\n",
    "    print(f\"Eval: {subj}\\t{mod_eval_data[subj]['raw_EEG'].shape}\") # Step 2 Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that could bandpass filtered one subject\n",
    "def butter_bandpass_one_subject(data, subj, lowcut, highcut, fs, interval=None):\n",
    "\n",
    "    # STORE DATA LOCALLY RATHER THAN IN RAM (RAM updates)\n",
    "    os.makedirs(\"./preprocessed4\", exist_ok=True) # RAM updates\n",
    "    \n",
    "    print('Processing ', subj)\n",
    "    \n",
    "    # Create new key 'EEG_filtered' to store filtered EEG of each subject\n",
    "    data[subj]['EEG_filtered'] = {}\n",
    "    \n",
    "    # Current raw EEG\n",
    "    temp_raw_EEG = data[subj]['raw_EEG']\n",
    "    print(f\"{subj}: {temp_raw_EEG.shape}\")\n",
    "    \n",
    "    if interval is not None:\n",
    "        startband = np.arange(lowcut, highcut, step = interval)\n",
    "        \n",
    "        for start in startband:\n",
    "            # This will be new key inside the EEG_filtered\n",
    "            band = \"{:02d}_{:02d}\".format(start, start+interval)\n",
    "            \n",
    "            print('Filtering through {} Hz band'.format(band))\n",
    "\n",
    "            # Save Memory Changes  vvv\n",
    "            filtered_EEG = butter_bandpass_filter(temp_raw_EEG, start, start+interval, fs) # temp var to hold filtered data\n",
    "\n",
    "            save_path = f\"./preprocessed4/{subj}_{band}_filtered.npz\" # pathway to save current preprocessed band\n",
    "            np.savez_compressed(save_path, EEG=filtered_EEG) # save processed band to pathway defined above\n",
    "            data[subj]['EEG_filtered'][band] = {}\n",
    "            data[subj]['EEG_filtered'][band]['file_path'] = save_path # store saved path in dictionary\n",
    "            \n",
    "            del filtered_EEG  # free memory to help later cells (can comment out)\n",
    "\n",
    "            # Save Memory Changes  ^^^\n",
    "\n",
    "            # # Bandpass filtering\n",
    "            # data[subj]['EEG_filtered'][band]['EEG_all'] = butter_bandpass_filter(temp_raw_EEG, start, start+interval, fs)\n",
    "            # print(f\"{subj}_{band}\\t{data[subj]['EEG_filtered'][band]['EEG_all'].shape}\")\n",
    "    else:\n",
    "        # This will be new key inside the EEG_filtered\n",
    "        band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
    "\n",
    "        # Save Memory Changes  vvv\n",
    "        filtered_EEG = butter_bandpass_filter(temp_raw_EEG, lowcut, highcut, fs) # temp var to hold filtered data\n",
    "\n",
    "        save_path = f\"./preprocessed4/{subj}_{band}_filtered.npz\" # pathway to save current preprocessed band\n",
    "        np.savez_compressed(save_path, EEG=filtered_EEG) # save processed band to pathway defined above\n",
    "        data[subj]['EEG_filtered'][band]['file_path'] = save_path # store saved path in dictionary\n",
    "        \n",
    "        del filtered_EEG  # free memory to help later cells (can comment out)\n",
    "\n",
    "        # Save Memory Changes  ^^^\n",
    "\n",
    "        # data[subj]['EEG_filtered'][band]['EEG_all'] = butter_bandpass_filter(temp_raw_EEG, lowcut, highcut, fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_one_subject_eval(eval_data_dict, subj, lowcut, highcut, fs, interval=None):\n",
    "    os.makedirs(\"./preprocessed4_eval\", exist_ok=True)\n",
    "\n",
    "    print(f\"\\nProcessing eval subject {subj}\")\n",
    "    \n",
    "    # Extract raw EEG\n",
    "    temp_raw_EEG = eval_data_dict[subj]['raw_EEG']\n",
    "    print(f\"  Raw EEG shape: {temp_raw_EEG.shape}\")\n",
    "    \n",
    "    # Prepare dict for saving paths\n",
    "    eval_data_dict[subj]['EEG_filtered'] = {}\n",
    "\n",
    "    if interval is not None:\n",
    "        startband = np.arange(lowcut, highcut, step=interval)\n",
    "        for start in startband:\n",
    "            band = \"{:02d}_{:02d}\".format(start, start + interval)\n",
    "            print(f\"  🔍 Filtering {band} Hz\")\n",
    "\n",
    "            # Apply bandpass filter\n",
    "            filtered_EEG = butter_bandpass_filter(temp_raw_EEG, start, start + interval, fs)\n",
    "\n",
    "            # Save to file\n",
    "            save_path = f\"./preprocessed4_eval/{subj}_{band}_eval_filtered.npz\"\n",
    "            np.savez_compressed(save_path, EEG=filtered_EEG)\n",
    "\n",
    "            # Store file path in dictionary\n",
    "            eval_data_dict[subj]['EEG_filtered'][band] = {'file_path': save_path}\n",
    "            print(f\"     💾 Saved to {save_path} | Shape: {filtered_EEG.shape}\")\n",
    "\n",
    "            del filtered_EEG  # optional for memory\n",
    "    else:\n",
    "        # One band only\n",
    "        band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
    "        filtered_EEG = butter_bandpass_filter(temp_raw_EEG, lowcut, highcut, fs)\n",
    "        save_path = f\"./preprocessed4_eval/{subj}_{band}_eval_filtered.npz\"\n",
    "        np.savez_compressed(save_path, EEG=filtered_EEG)\n",
    "        eval_data_dict[subj]['EEG_filtered'][band] = {'file_path': save_path}\n",
    "        print(f\"  💾 Saved to {save_path} | Shape: {filtered_EEG.shape}\")\n",
    "        del filtered_EEG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bandpass filtering all subject (TRAIN DATA)\n",
    "# lowcut=4\n",
    "# highcut=40\n",
    "# fs = 250\n",
    "# ns = 10\n",
    "\n",
    "# # Iterate over all subjects\n",
    "# for i in range(1, ns):\n",
    "#     subj = subject_counter(i)\n",
    "#     butter_bandpass_one_subject(mod_data, subj, lowcut, highcut, fs, interval=4)\n",
    "#     # print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing eval subject subject01\n",
      "  Raw EEG shape: (22, 687000)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_04_08_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_08_12_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_12_16_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_16_20_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_20_24_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_24_28_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_28_32_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_32_36_eval_filtered.npz | Shape: (22, 687000)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject01_36_40_eval_filtered.npz | Shape: (22, 687000)\n",
      "\n",
      "Processing eval subject subject02\n",
      "  Raw EEG shape: (22, 662666)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_04_08_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_08_12_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_12_16_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_16_20_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_20_24_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_24_28_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_28_32_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_32_36_eval_filtered.npz | Shape: (22, 662666)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject02_36_40_eval_filtered.npz | Shape: (22, 662666)\n",
      "\n",
      "Processing eval subject subject03\n",
      "  Raw EEG shape: (22, 648775)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_04_08_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_08_12_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_12_16_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_16_20_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_20_24_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_24_28_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_28_32_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_32_36_eval_filtered.npz | Shape: (22, 648775)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject03_36_40_eval_filtered.npz | Shape: (22, 648775)\n",
      "\n",
      "Processing eval subject subject04\n",
      "  Raw EEG shape: (22, 660047)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_04_08_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_08_12_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_12_16_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_16_20_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_20_24_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_24_28_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_28_32_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_32_36_eval_filtered.npz | Shape: (22, 660047)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject04_36_40_eval_filtered.npz | Shape: (22, 660047)\n",
      "\n",
      "Processing eval subject subject05\n",
      "  Raw EEG shape: (22, 679863)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_04_08_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_08_12_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_12_16_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_16_20_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_20_24_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_24_28_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_28_32_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_32_36_eval_filtered.npz | Shape: (22, 679863)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject05_36_40_eval_filtered.npz | Shape: (22, 679863)\n",
      "\n",
      "Processing eval subject subject06\n",
      "  Raw EEG shape: (22, 666373)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_04_08_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_08_12_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_12_16_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_16_20_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_20_24_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_24_28_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_28_32_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_32_36_eval_filtered.npz | Shape: (22, 666373)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject06_36_40_eval_filtered.npz | Shape: (22, 666373)\n",
      "\n",
      "Processing eval subject subject07\n",
      "  Raw EEG shape: (22, 673135)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_04_08_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_08_12_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_12_16_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_16_20_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_20_24_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_24_28_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_28_32_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_32_36_eval_filtered.npz | Shape: (22, 673135)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject07_36_40_eval_filtered.npz | Shape: (22, 673135)\n",
      "\n",
      "Processing eval subject subject08\n",
      "  Raw EEG shape: (22, 687792)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_04_08_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_08_12_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_12_16_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_16_20_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_20_24_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_24_28_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_28_32_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_32_36_eval_filtered.npz | Shape: (22, 687792)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject08_36_40_eval_filtered.npz | Shape: (22, 687792)\n",
      "\n",
      "Processing eval subject subject09\n",
      "  Raw EEG shape: (22, 675098)\n",
      "  🔍 Filtering 04_08 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_04_08_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 08_12 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_08_12_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 12_16 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_12_16_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 16_20 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_16_20_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 20_24 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_20_24_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 24_28 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_24_28_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 28_32 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_28_32_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 32_36 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_32_36_eval_filtered.npz | Shape: (22, 675098)\n",
      "  🔍 Filtering 36_40 Hz\n",
      "     💾 Saved to ./preprocessed4_eval/subject09_36_40_eval_filtered.npz | Shape: (22, 675098)\n"
     ]
    }
   ],
   "source": [
    "# Bandpass filtering all subject (EVAL DATA)\n",
    "\n",
    "lowcut=4\n",
    "highcut=40\n",
    "fs = 250\n",
    "ns = 10\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    butter_bandpass_one_subject_eval(mod_eval_data, subj, 4, 40, fs=250, interval=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking EEG data corresponds to left and right class (now all 4 classes)\n",
    "This work will only clasify two class, left and right hand, meanwhile the data contains four class,  \n",
    "thus the goal here is to make band-filtered EEG left and right of each class of shape T x C x N, where  \n",
    "T = trial, C = channel, N = sample\n",
    "\n",
    "### Step 1 modification:\n",
    "This work will now classify all four classes, left hand, right hand, feet, and tongue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First take the position of left and right class\n",
    "left_class_code = 769\n",
    "right_class_code = 770\n",
    "\n",
    "# Step 1 Modification:\n",
    "# Take the position of both feet (class 3) and tongue (class 4) classes\n",
    "feet_class_code = 771\n",
    "tongue_class_code = 772\n",
    "\n",
    "for i in range(1, ns): # replaced 4 with ns (step 0)\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    mod_data[subj]['left_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == left_class_code]\n",
    "    mod_data[subj]['right_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == right_class_code]\n",
    "    \n",
    "    # step 1 modifications:\n",
    "    mod_data[subj]['feet_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == feet_class_code]\n",
    "    mod_data[subj]['tongue_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == tongue_class_code]\n",
    "\n",
    "    # step 2 modifications:\n",
    "    mod_eval_data[subj]['left_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == left_class_code]\n",
    "    mod_eval_data[subj]['right_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == right_class_code]\n",
    "    mod_eval_data[subj]['feet_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == feet_class_code]\n",
    "    mod_eval_data[subj]['tongue_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == tongue_class_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mod_data and mod_eval_data rebuilt successfully from saved files (4-class).\n"
     ]
    }
   ],
   "source": [
    "# Rebuild mod_data and mod_eval_data from saved, preprocessed .npz files for 4-class classification\n",
    "\n",
    "# 👇 REBUILD `mod_data` and `mod_eval_data` STRUCTURES FROM SAVED FILES (4-class) 👇\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mod_data = {}\n",
    "mod_eval_data = {}\n",
    "ori_data = {}\n",
    "eval_data = {}\n",
    "\n",
    "bands = [\"{:02d}_{:02d}\".format(i, i+4) for i in range(4, 40, 4)]  # 4 Hz bands\n",
    "ns = 10  # number of subjects\n",
    "fs = 250  # sampling frequency (Hz)\n",
    "\n",
    "# Rebuild from saved filtered .npz files and raw .npz files\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    mod_data[subj] = {}\n",
    "    mod_eval_data[subj] = {}\n",
    "    \n",
    "    mod_data[subj]['EEG_filtered'] = {}\n",
    "    mod_eval_data[subj]['EEG_filtered'] = {}\n",
    "    \n",
    "    # Load original raw training and evaluation metadata to extract event positions (4 classes)\n",
    "    ori_data[subj] = np.load(f\"A{i:02d}T.npz\")\n",
    "    eval_data[subj] = np.load(f\"A{i:02d}E.npz\")\n",
    "    \n",
    "    # Training trial positions (from AxxT)\n",
    "    mod_data[subj]['left_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == 769]\n",
    "    mod_data[subj]['right_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == 770]\n",
    "    mod_data[subj]['feet_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == 771]\n",
    "    mod_data[subj]['tongue_pos'] = ori_data[subj]['epos'][ori_data[subj]['etyp'] == 772]\n",
    "    \n",
    "    # Evaluation trial positions (from AxxE)\n",
    "    mod_eval_data[subj]['left_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == 769]\n",
    "    mod_eval_data[subj]['right_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == 770]\n",
    "    mod_eval_data[subj]['feet_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == 771]\n",
    "    mod_eval_data[subj]['tongue_pos'] = eval_data[subj]['epos'][eval_data[subj]['etyp'] == 772]\n",
    "    \n",
    "    # Rebuild file paths for each band\n",
    "    for band in bands:\n",
    "        # Training EEG paths\n",
    "        train_path = f\"./preprocessed4/{subj}_{band}_filtered.npz\"\n",
    "        if not os.path.exists(train_path):\n",
    "            raise FileNotFoundError(f\"Missing training preprocessed file: {train_path}\")\n",
    "        mod_data[subj]['EEG_filtered'][band] = {\n",
    "            'file_path': train_path\n",
    "        }\n",
    "        \n",
    "        # Evaluation EEG paths\n",
    "        eval_path = f\"./preprocessed4_eval/{subj}_{band}_eval_filtered.npz\"\n",
    "        if not os.path.exists(eval_path):\n",
    "            raise FileNotFoundError(f\"Missing evaluation preprocessed file: {eval_path}\")\n",
    "        mod_eval_data[subj]['EEG_filtered'][band] = {\n",
    "            'file_path': eval_path\n",
    "        }\n",
    "\n",
    "    # LOGGING vvvv\n",
    "    # print(f\"[{subj}] Loaded band files:\")\n",
    "    # for band in bands:\n",
    "    #     print(f\"  🟢 {band} - train: {mod_data[subj]['EEG_filtered'][band]['file_path']}\")\n",
    "    #     print(f\"  🟡 {band} - eval : {mod_eval_data[subj]['EEG_filtered'][band]['file_path']}\")\n",
    "\n",
    "\n",
    "print(\"✅ mod_data and mod_eval_data rebuilt successfully from saved files (4-class).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WE TAKE DATA WITHIN [0.5 3.5] SECONDS RIGHT HERE \n",
    "VVVVV                                   VVVVVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject01\n",
      "[subject01 - 04_08] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 08_12] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 12_16] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 16_20] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 20_24] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 24_28] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 28_32] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 32_36] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject01 - 36_40] EEG loaded shape: (22, 672528)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject02\n",
      "[subject02 - 04_08] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 08_12] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 12_16] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 16_20] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 20_24] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 24_28] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 28_32] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 32_36] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject02 - 36_40] EEG loaded shape: (22, 677169)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject03\n",
      "[subject03 - 04_08] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 08_12] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 12_16] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 16_20] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 20_24] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 24_28] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 28_32] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 32_36] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject03 - 36_40] EEG loaded shape: (22, 660530)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject04\n",
      "[subject04 - 04_08] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 08_12] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 12_16] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 16_20] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 20_24] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 24_28] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 28_32] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 32_36] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject04 - 36_40] EEG loaded shape: (22, 600915)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject05\n",
      "[subject05 - 04_08] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 08_12] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 12_16] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 16_20] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 20_24] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 24_28] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 28_32] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 32_36] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject05 - 36_40] EEG loaded shape: (22, 686120)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject06\n",
      "[subject06 - 04_08] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 08_12] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 12_16] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 16_20] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 20_24] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 24_28] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 28_32] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 32_36] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject06 - 36_40] EEG loaded shape: (22, 678980)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject07\n",
      "[subject07 - 04_08] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 08_12] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 12_16] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 16_20] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 20_24] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 24_28] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 28_32] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 32_36] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject07 - 36_40] EEG loaded shape: (22, 681071)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject08\n",
      "[subject08 - 04_08] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 08_12] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 12_16] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 16_20] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 20_24] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 24_28] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 28_32] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 32_36] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject08 - 36_40] EEG loaded shape: (22, 675270)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "Processing subject09\n",
      "[subject09 - 04_08] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 08_12] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 12_16] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 16_20] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 20_24] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 24_28] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 28_32] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 32_36] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n",
      "[subject09 - 36_40] EEG loaded shape: (22, 673328)\n",
      "  Trials - Left: 72, Right: 72, Feet: 72, Tongue: 72\n",
      "  Segments - Left: (72, 22, 750), Right: (72, 22, 750), Feet: (72, 22, 750), Tongue: (72, 22, 750)\n"
     ]
    }
   ],
   "source": [
    "# Now take EEG data within [0.5 3.5] seconds after cue onset position of each class\n",
    "start = 0.5\n",
    "end = 3.5\n",
    "\n",
    "samples_start = int(start * fs)\n",
    "samples_end = int(end * fs)\n",
    "\n",
    "# Please modify this range to add more subjects\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    print('Processing', subj)\n",
    "    \n",
    "    # Temporary variable of left and right pos    \n",
    "    temp_pos_left = mod_data[subj]['left_pos']\n",
    "    temp_pos_right = mod_data[subj]['right_pos']\n",
    "\n",
    "    # Temporary variable of feet and tongue pos    \n",
    "    temp_pos_feet = mod_data[subj]['feet_pos']  # step 1 modification\n",
    "    temp_pos_tongue = mod_data[subj]['tongue_pos']  # step 1 modification\n",
    " \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        # 🔥 Load the preprocessed EEG for the current band (because we stored only file paths)\n",
    "        loaded_data = np.load(mod_data[subj]['EEG_filtered'][band]['file_path'])\n",
    "        temp_EEG_all = loaded_data['EEG']  # EEG shape: channels × samples\n",
    "\n",
    "        temp_EEG_left = []\n",
    "        temp_EEG_right = []\n",
    "        temp_EEG_feet = []  # step 1 modification\n",
    "        temp_EEG_tongue = []  # step 1 modification\n",
    "        \n",
    "        # LEFT\n",
    "        for j in range(len(temp_pos_left)):\n",
    "            temp_EEG_left.append(temp_EEG_all[:, temp_pos_left[j] + samples_start : temp_pos_left[j] + samples_end])\n",
    "        mod_data[subj]['EEG_filtered'][band]['EEG_left'] = np.array(temp_EEG_left)\n",
    "        \n",
    "        # RIGHT\n",
    "        for j in range(len(temp_pos_right)):\n",
    "            temp_EEG_right.append(temp_EEG_all[:, temp_pos_right[j] + samples_start : temp_pos_right[j] + samples_end])\n",
    "        mod_data[subj]['EEG_filtered'][band]['EEG_right'] = np.array(temp_EEG_right)\n",
    "\n",
    "        # step 1 modifications\n",
    "        # FEET\n",
    "        for j in range(len(temp_pos_feet)):\n",
    "            temp_EEG_feet.append(temp_EEG_all[:, temp_pos_feet[j] + samples_start : temp_pos_feet[j] + samples_end])\n",
    "        mod_data[subj]['EEG_filtered'][band]['EEG_feet'] = np.array(temp_EEG_feet)\n",
    "        \n",
    "        # TONGUE\n",
    "        for j in range(len(temp_pos_tongue)):\n",
    "            temp_EEG_tongue.append(temp_EEG_all[:, temp_pos_tongue[j] + samples_start : temp_pos_tongue[j] + samples_end])\n",
    "        mod_data[subj]['EEG_filtered'][band]['EEG_tongue'] = np.array(temp_EEG_tongue)\n",
    "        \n",
    "        loaded_data.close()  # close the .npz file\n",
    "        print(f\"[{subj} - {band}] EEG loaded shape: {temp_EEG_all.shape}\")\n",
    "\n",
    "        # Print class trial counts and resulting shapes\n",
    "        print(f\"  Trials - Left: {len(temp_pos_left)}, Right: {len(temp_pos_right)}, Feet: {len(temp_pos_feet)}, Tongue: {len(temp_pos_tongue)}\")\n",
    "        print(f\"  Segments - Left: {np.array(temp_EEG_left).shape}, Right: {np.array(temp_EEG_right).shape}, Feet: {np.array(temp_EEG_feet).shape}, Tongue: {np.array(temp_EEG_tongue).shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing EVALUATION data for subject01\n",
      "[subject01 - 04_08] 288 evaluation segments extracted.\n",
      "[subject01 - 08_12] 288 evaluation segments extracted.\n",
      "[subject01 - 12_16] 288 evaluation segments extracted.\n",
      "[subject01 - 16_20] 288 evaluation segments extracted.\n",
      "[subject01 - 20_24] 288 evaluation segments extracted.\n",
      "[subject01 - 24_28] 288 evaluation segments extracted.\n",
      "[subject01 - 28_32] 288 evaluation segments extracted.\n",
      "[subject01 - 32_36] 288 evaluation segments extracted.\n",
      "[subject01 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject02\n",
      "[subject02 - 04_08] 288 evaluation segments extracted.\n",
      "[subject02 - 08_12] 288 evaluation segments extracted.\n",
      "[subject02 - 12_16] 288 evaluation segments extracted.\n",
      "[subject02 - 16_20] 288 evaluation segments extracted.\n",
      "[subject02 - 20_24] 288 evaluation segments extracted.\n",
      "[subject02 - 24_28] 288 evaluation segments extracted.\n",
      "[subject02 - 28_32] 288 evaluation segments extracted.\n",
      "[subject02 - 32_36] 288 evaluation segments extracted.\n",
      "[subject02 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject03\n",
      "[subject03 - 04_08] 288 evaluation segments extracted.\n",
      "[subject03 - 08_12] 288 evaluation segments extracted.\n",
      "[subject03 - 12_16] 288 evaluation segments extracted.\n",
      "[subject03 - 16_20] 288 evaluation segments extracted.\n",
      "[subject03 - 20_24] 288 evaluation segments extracted.\n",
      "[subject03 - 24_28] 288 evaluation segments extracted.\n",
      "[subject03 - 28_32] 288 evaluation segments extracted.\n",
      "[subject03 - 32_36] 288 evaluation segments extracted.\n",
      "[subject03 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject04\n",
      "[subject04 - 04_08] 288 evaluation segments extracted.\n",
      "[subject04 - 08_12] 288 evaluation segments extracted.\n",
      "[subject04 - 12_16] 288 evaluation segments extracted.\n",
      "[subject04 - 16_20] 288 evaluation segments extracted.\n",
      "[subject04 - 20_24] 288 evaluation segments extracted.\n",
      "[subject04 - 24_28] 288 evaluation segments extracted.\n",
      "[subject04 - 28_32] 288 evaluation segments extracted.\n",
      "[subject04 - 32_36] 288 evaluation segments extracted.\n",
      "[subject04 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject05\n",
      "[subject05 - 04_08] 288 evaluation segments extracted.\n",
      "[subject05 - 08_12] 288 evaluation segments extracted.\n",
      "[subject05 - 12_16] 288 evaluation segments extracted.\n",
      "[subject05 - 16_20] 288 evaluation segments extracted.\n",
      "[subject05 - 20_24] 288 evaluation segments extracted.\n",
      "[subject05 - 24_28] 288 evaluation segments extracted.\n",
      "[subject05 - 28_32] 288 evaluation segments extracted.\n",
      "[subject05 - 32_36] 288 evaluation segments extracted.\n",
      "[subject05 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject06\n",
      "[subject06 - 04_08] 288 evaluation segments extracted.\n",
      "[subject06 - 08_12] 288 evaluation segments extracted.\n",
      "[subject06 - 12_16] 288 evaluation segments extracted.\n",
      "[subject06 - 16_20] 288 evaluation segments extracted.\n",
      "[subject06 - 20_24] 288 evaluation segments extracted.\n",
      "[subject06 - 24_28] 288 evaluation segments extracted.\n",
      "[subject06 - 28_32] 288 evaluation segments extracted.\n",
      "[subject06 - 32_36] 288 evaluation segments extracted.\n",
      "[subject06 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject07\n",
      "[subject07 - 04_08] 288 evaluation segments extracted.\n",
      "[subject07 - 08_12] 288 evaluation segments extracted.\n",
      "[subject07 - 12_16] 288 evaluation segments extracted.\n",
      "[subject07 - 16_20] 288 evaluation segments extracted.\n",
      "[subject07 - 20_24] 288 evaluation segments extracted.\n",
      "[subject07 - 24_28] 288 evaluation segments extracted.\n",
      "[subject07 - 28_32] 288 evaluation segments extracted.\n",
      "[subject07 - 32_36] 288 evaluation segments extracted.\n",
      "[subject07 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject08\n",
      "[subject08 - 04_08] 288 evaluation segments extracted.\n",
      "[subject08 - 08_12] 288 evaluation segments extracted.\n",
      "[subject08 - 12_16] 288 evaluation segments extracted.\n",
      "[subject08 - 16_20] 288 evaluation segments extracted.\n",
      "[subject08 - 20_24] 288 evaluation segments extracted.\n",
      "[subject08 - 24_28] 288 evaluation segments extracted.\n",
      "[subject08 - 28_32] 288 evaluation segments extracted.\n",
      "[subject08 - 32_36] 288 evaluation segments extracted.\n",
      "[subject08 - 36_40] 288 evaluation segments extracted.\n",
      "Processing EVALUATION data for subject09\n",
      "[subject09 - 04_08] 288 evaluation segments extracted.\n",
      "[subject09 - 08_12] 288 evaluation segments extracted.\n",
      "[subject09 - 12_16] 288 evaluation segments extracted.\n",
      "[subject09 - 16_20] 288 evaluation segments extracted.\n",
      "[subject09 - 20_24] 288 evaluation segments extracted.\n",
      "[subject09 - 24_28] 288 evaluation segments extracted.\n",
      "[subject09 - 28_32] 288 evaluation segments extracted.\n",
      "[subject09 - 32_36] 288 evaluation segments extracted.\n",
      "[subject09 - 36_40] 288 evaluation segments extracted.\n"
     ]
    }
   ],
   "source": [
    "# # Now take EEG EVALUATION data within [0.5 3.5] seconds after cue onset position of each class\n",
    "# start = 0.5\n",
    "# end = 3.5\n",
    "\n",
    "# samples_start = int(start * fs)\n",
    "# samples_end = int(end * fs)\n",
    "\n",
    "# # Please modify this range to add more subjects\n",
    "# for i in range(1, ns):\n",
    "#     subj = subject_counter(i)\n",
    "#     print('Processing EVALUATION data for', subj)\n",
    "    \n",
    "#     # Temporary variable of left and right eval pos    \n",
    "#     temp_pos_left = mod_eval_data[subj]['left_pos']\n",
    "#     temp_pos_right = mod_eval_data[subj]['right_pos']\n",
    "\n",
    "#     # Temporary variable of feet and tongue eval pos    \n",
    "#     temp_pos_feet = mod_eval_data[subj]['feet_pos']  # step 1 modification\n",
    "#     temp_pos_tongue = mod_eval_data[subj]['tongue_pos']  # step 1 modification\n",
    " \n",
    "#     for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "#         # 🔥 Load the preprocessed EVALUATION EEG for the current band\n",
    "#         loaded_data = np.load(mod_eval_data[subj]['EEG_filtered'][band]['file_path'])\n",
    "#         temp_EEG_all = loaded_data['EEG']  # EEG shape: channels × samples\n",
    "        \n",
    "#         temp_EEG_left = []\n",
    "#         temp_EEG_right = []\n",
    "#         temp_EEG_feet = []  # step 1 modification\n",
    "#         temp_EEG_tongue = []  # step 1 modification\n",
    "        \n",
    "#         # LEFT\n",
    "#         for j in range(len(temp_pos_left)):\n",
    "#             temp_EEG_left.append(temp_EEG_all[:, temp_pos_left[j] + samples_start : temp_pos_left[j] + samples_end])\n",
    "#         mod_eval_data[subj]['EEG_filtered'][band]['EEG_left'] = np.array(temp_EEG_left)\n",
    "        \n",
    "#         # RIGHT\n",
    "#         for j in range(len(temp_pos_right)):\n",
    "#             temp_EEG_right.append(temp_EEG_all[:, temp_pos_right[j] + samples_start : temp_pos_right[j] + samples_end])\n",
    "#         mod_eval_data[subj]['EEG_filtered'][band]['EEG_right'] = np.array(temp_EEG_right)\n",
    "\n",
    "#         # step 1 modifications\n",
    "#         # FEET\n",
    "#         for j in range(len(temp_pos_feet)):\n",
    "#             temp_EEG_feet.append(temp_EEG_all[:, temp_pos_feet[j] + samples_start : temp_pos_feet[j] + samples_end])\n",
    "#         mod_eval_data[subj]['EEG_filtered'][band]['EEG_feet'] = np.array(temp_EEG_feet)\n",
    "        \n",
    "#         # TONGUE\n",
    "#         for j in range(len(temp_pos_tongue)):\n",
    "#             temp_EEG_tongue.append(temp_EEG_all[:, temp_pos_tongue[j] + samples_start : temp_pos_tongue[j] + samples_end])\n",
    "#         mod_eval_data[subj]['EEG_filtered'][band]['EEG_tongue'] = np.array(temp_EEG_tongue)\n",
    "        \n",
    "#         loaded_data.close()  # close the .npz file\n",
    "#         print(f\"[{subj} - {band}] EEG loaded shape: {temp_EEG_all.shape}\")\n",
    "\n",
    "#         # Print class trial counts and resulting shapes\n",
    "#         print(f\"  Trials - Left: {len(temp_pos_left)}, Right: {len(temp_pos_right)}, Feet: {len(temp_pos_feet)}, Tongue: {len(temp_pos_tongue)}\")\n",
    "#         print(f\"  Segments - Left: {np.array(temp_EEG_left).shape}, Right: {np.array(temp_EEG_right).shape}, Feet: {np.array(temp_EEG_feet).shape}, Tongue: {np.array(temp_EEG_tongue).shape}\")\n",
    "\n",
    "\n",
    "# ✅ CORRECT WAY: Extract ALL trials in eval set (no class labels!)\n",
    "\n",
    "start = 0.5\n",
    "end = 3.5\n",
    "samples_start = int(start * fs)\n",
    "samples_end = int(end * fs)\n",
    "\n",
    "cue_code = 768  # This is the start-of-trial event\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    print('Processing EVALUATION data for', subj)\n",
    "    \n",
    "    cue_positions = eval_data[subj]['epos'][eval_data[subj]['etyp'] == cue_code]\n",
    "\n",
    "    for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "        # Load preprocessed EEG for the current band\n",
    "        loaded_data = np.load(mod_eval_data[subj]['EEG_filtered'][band]['file_path'])\n",
    "        temp_EEG_all = loaded_data['EEG']  # Shape: (channels, samples)\n",
    "\n",
    "        trial_segments = []\n",
    "        for pos in cue_positions:\n",
    "            segment = temp_EEG_all[:, pos + samples_start : pos + samples_end]\n",
    "            trial_segments.append(segment)\n",
    "\n",
    "        mod_eval_data[subj]['EEG_filtered'][band]['eval_trials'] = np.array(trial_segments)\n",
    "        loaded_data.close()\n",
    "\n",
    "        print(f\"[{subj} - {band}] {len(trial_segments)} evaluation segments extracted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_EEG_one_class(EEG_one_class, percent_train=0.8):\n",
    "#     '''\n",
    "#     split_EEG_one_class will receive EEG data of one class, with size of T x N x M, where\n",
    "#     T = number of trial\n",
    "#     N = number of electrodes\n",
    "#     M = sample number\n",
    "    \n",
    "#     INPUT:\n",
    "#     EEG_data_one_class: the data of one class of EEG data\n",
    "    \n",
    "#     percent_train: allocation percentage of training data, default is 0.8\n",
    "    \n",
    "#     OUTPUT:\n",
    "#     EEG_train: EEG data for training\n",
    "    \n",
    "#     EEG_test: EEG data for test\n",
    "    \n",
    "#     Both have type of np.arrray dimension of T x M x N\n",
    "#     '''\n",
    "\n",
    "#     # Number of all trials\n",
    "#     n = EEG_one_class.shape[0]\n",
    "    \n",
    "#     n_tr = round(n*percent_train)\n",
    "#     n_te = n - n_tr\n",
    "    \n",
    "#     EEG_train = EEG_one_class[:n_tr]\n",
    "#     EEG_test = EEG_one_class[n_tr:n_tr+n_te]\n",
    "        \n",
    "#     return EEG_train, EEG_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all subjects\n",
    "for i in range(1, ns):\n",
    "    \n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    # Iterate over all bands\n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        \n",
    "        # Temporary variable for left and right class of each band\n",
    "        temp_EEG_left = mod_data[subj]['EEG_filtered'][band]['EEG_left']\n",
    "        temp_EEG_right = mod_data[subj]['EEG_filtered'][band]['EEG_right']\n",
    "\n",
    "        # step 1 modifications\n",
    "        # Temporary variable for feet and tongue class of each band\n",
    "        temp_EEG_feet = mod_data[subj]['EEG_filtered'][band]['EEG_feet'] # step 1 addition\n",
    "        temp_EEG_tongue = mod_data[subj]['EEG_filtered'][band]['EEG_tongue'] # step 1 addition\n",
    "\n",
    "        # Temporary variable to access each band\n",
    "        temp_filt = mod_data[subj]['EEG_filtered'][band]\n",
    "        \n",
    "        # temp_filt['EEG_left_train'], temp_filt['EEG_left_test'] = split_EEG_one_class(temp_EEG_left, 0.8)\n",
    "        # temp_filt['EEG_right_train'], temp_filt['EEG_right_test'] = split_EEG_one_class(temp_EEG_right, 0.8)  \n",
    "        \n",
    "        # # step 1 modifications:\n",
    "        # temp_filt['EEG_feet_train'], temp_filt['EEG_feet_test'] = split_EEG_one_class(temp_EEG_feet, 0.8) # step 1 addition\n",
    "        # temp_filt['EEG_tongue_train'], temp_filt['EEG_tongue_test'] = split_EEG_one_class(temp_EEG_tongue, 0.8) # step 1 addition\n",
    "        \n",
    "        # STEP 2 MODIFICATIONS: (use 100% of train data, i.e. A0XT files)\n",
    "        temp_filt['EEG_left_train'] = temp_EEG_left\n",
    "        temp_filt['EEG_right_train'] = temp_EEG_right\n",
    "        temp_filt['EEG_feet_train'] = temp_EEG_feet\n",
    "        temp_filt['EEG_tongue_train'] = temp_EEG_tongue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_data['subject01']['EEG_filtered']['04_08'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP\n",
    "This step will perform CSP on each band of each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all subject create new keys to store all result in CSP step\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    mod_data[subj]['CSP'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Composite Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cov(EEG_data):\n",
    "    '''\n",
    "    INPUT:\n",
    "    EEG_data : EEG_data in shape T x N x S\n",
    "    \n",
    "    OUTPUT:\n",
    "    avg_cov : covariance matrix of averaged over all trials\n",
    "    '''\n",
    "    cov = []\n",
    "    for i in range(EEG_data.shape[0]):\n",
    "        cov.append(EEG_data[i]@EEG_data[i].T/np.trace(EEG_data[i]@EEG_data[i].T))\n",
    "        \n",
    "    cov = np.mean(np.array(cov), 0)\n",
    "    \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all subjects\n",
    "for i in range(1, ns):\n",
    "    \n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    # Iterate over all bands\n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        \n",
    "        # New key to store result\n",
    "        temp_band = mod_data[subj]['CSP'][band] = {}\n",
    "        \n",
    "        # Compute left and right covariance\n",
    "        # LEFT\n",
    "        temp_band['cov_left'] = compute_cov(mod_data[subj]['EEG_filtered'][band]['EEG_left'])\n",
    "        \n",
    "        # RIGHT\n",
    "        temp_band['cov_right'] = compute_cov(mod_data[subj]['EEG_filtered'][band]['EEG_right'])\n",
    "\n",
    "        # Step 1 Modifications: compute feet and tongue covariance\n",
    "        # FEET\n",
    "        temp_band['cov_feet'] = compute_cov(mod_data[subj]['EEG_filtered'][band]['EEG_feet']) # step 1 addition\n",
    "        \n",
    "        # TONGUE\n",
    "        temp_band['cov_tongue'] = compute_cov(mod_data[subj]['EEG_filtered'][band]['EEG_tongue']) # step 1 addition\n",
    "\n",
    "        \n",
    "        # Add covariance of left and right class as composite covariance\n",
    "        temp_band['cov_comp'] = temp_band['cov_left'] + temp_band['cov_right'] + temp_band[\"cov_feet\"] + temp_band[\"cov_tongue\"] # last 2 step 1 addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp1 = mod_data['subject03']['CSP']['04_08']['cov_left']\n",
    "# temp2 = mod_data['subject03']['CSP']['04_08']['cov_right']\n",
    "# temp3 = mod_data['subject03']['CSP']['04_08']['cov_comp']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Matrix (P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new keys for result in whitening step\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        mod_data[subj]['CSP'][band]['whitening'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "from scipy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_cov(avg_cov):\n",
    "    '''\n",
    "    This function will decompose average covariance matrix of one class of each subject into \n",
    "    eigenvalues denoted by lambda and eigenvector denoted by V\n",
    "    Both will be in descending order\n",
    "    \n",
    "    Parameter:\n",
    "    avgCov = the averaged covariance of one class\n",
    "    \n",
    "    Return:\n",
    "    λ_dsc and V_dsc, i.e. eigenvalues and eigenvector in descending order\n",
    "    \n",
    "    '''\n",
    "    λ, V = np.linalg.eig(avg_cov)\n",
    "    λ_dsc = np.sort(λ)[::-1] # Sort eigenvalue descending order, default is ascending order sort\n",
    "    idx_dsc = np.argsort(λ)[::-1] # Find index in descending order\n",
    "    V_dsc = V[:, idx_dsc] # Sort eigenvectors descending order\n",
    "    λ_dsc = np.diag(λ_dsc) # Diagonalize λ_dsc\n",
    "    \n",
    "    return λ_dsc, V_dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_matrix(λ_dsc, V_dsc):\n",
    "    '''\n",
    "    '''\n",
    "    λ_dsc_sqr = sqrtm(inv(λ_dsc))\n",
    "    P = (λ_dsc_sqr)@(V_dsc.T)\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all subject compute whitening matrix\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        \n",
    "        temp_whitening = mod_data[subj]['CSP'][band]['whitening']\n",
    "\n",
    "        temp_cov = mod_data[subj]['CSP'][band]['cov_comp']\n",
    "\n",
    "        # Decomposing composite covariance into eigenvector and eigenvalue\n",
    "        temp_whitening['eigval'], temp_whitening['eigvec'] = decompose_cov(temp_cov)\n",
    "\n",
    "        # White matrix\n",
    "        temp_whitening['P'] = white_matrix(temp_whitening['eigval'], temp_whitening['eigvec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Eigenvec from Sl and Sr\n",
    "In this step the Sl and Sr will not be stored, will only be used to compute each eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new keys for result in whitening step\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        mod_data[subj]['CSP'][band]['S_left'] = {}\n",
    "        mod_data[subj]['CSP'][band]['S_right'] = {}  \n",
    "        mod_data[subj]['CSP'][band]['S_feet'] = {} # step 1 addition\n",
    "        mod_data[subj]['CSP'][band]['S_tongue'] = {} # step 1 addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_S(avg_Cov, white):\n",
    "    '''\n",
    "    This function will compute S matrix, S = P * C * P.T\n",
    "\n",
    "    INPUT:\n",
    "    avg_Cov: averaged covariance of one class, dimension N x N, where N is number of electrodes\n",
    "    white: the whitening transformation matrix\n",
    "    \n",
    "    OUTPUT:\n",
    "    S\n",
    "    '''\n",
    "    S = white@avg_Cov@white.T\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_S(S_one_class, order='descending'):\n",
    "    '''\n",
    "    This function will decompose the S matrix of one class to get the eigen vector\n",
    "    Both eigenvector will be the same but in opposite order\n",
    "    \n",
    "    i.e the highest eigenvector in S left will be equal to lowest eigenvector in S right matrix \n",
    "    '''\n",
    "    # Decompose S\n",
    "    λ, B = np.linalg.eig(S_one_class)\n",
    "    \n",
    "    # Sort eigenvalues either descending or ascending\n",
    "    if order == 'ascending':\n",
    "        idx = λ.argsort() # Use this index to sort eigenvector smallest -> largest\n",
    "    elif order == 'descending':\n",
    "        idx = λ.argsort()[::-1] # Use this index to sort eigenvector largest -> smallest\n",
    "    else:\n",
    "        print('Wrong order input')\n",
    "    \n",
    "    λ = λ[idx]\n",
    "    B = B[:, idx]\n",
    "    \n",
    "    return B, λ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all subjects\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        # Where to access data\n",
    "        temp_P = mod_data[subj]['CSP'][band]['whitening']['P']\n",
    "        Cl = mod_data[subj]['CSP'][band]['cov_left']\n",
    "        Cr = mod_data[subj]['CSP'][band]['cov_right']\n",
    "        Cf = mod_data[subj]['CSP'][band]['cov_feet'] # step 1 addition\n",
    "        Ct = mod_data[subj]['CSP'][band]['cov_tongue'] # step 1 addition\n",
    "\n",
    "        # Where to store result\n",
    "        # print(f\"Band: {band}\\tKeys: {mod_data[subj]['CSP'][band].keys()}\") # used for debugging on key error\n",
    "        temp_Sl = mod_data[subj]['CSP'][band]['S_left']\n",
    "        temp_Sr = mod_data[subj]['CSP'][band]['S_right']\n",
    "        temp_Sf = mod_data[subj]['CSP'][band]['S_feet'] # step 1 addition\n",
    "        temp_St = mod_data[subj]['CSP'][band]['S_tongue'] # step 1 addition\n",
    "\n",
    "        # LEFT\n",
    "        Sl = compute_S(Cl, temp_P)\n",
    "        temp_Sl['eigvec'], temp_Sl['eigval'] = decompose_S(Sl, 'descending')\n",
    "\n",
    "        # RIGHT\n",
    "        Sr = compute_S(Cr, temp_P)\n",
    "        temp_Sr['eigvec'], temp_Sr['eigval'] = decompose_S(Sr, 'ascending')   \n",
    "\n",
    "        # step 1 addition; add calculations for feet and tongue classes as well\n",
    "\n",
    "        # FEET\n",
    "        Sf = compute_S(Cf, temp_P)\n",
    "        temp_Sf['eigvec'], temp_Sf['eigval'] = decompose_S(Sf, 'descending')\n",
    "\n",
    "        # TONGUE\n",
    "        St = compute_S(Ct, temp_P)\n",
    "        temp_St['eigvec'], temp_St['eigval'] = decompose_S(St, 'ascending')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking eigenvalues\n",
    "# temp1 = mod_data['subject02']['CSP'][band]['S_left']['eigval']\n",
    "# temp2 = mod_data['subject02']['CSP'][band]['S_right']['eigval']\n",
    "# temp3 = mod_data['subject02']['CSP'][band]['S_feet']['eigval']\n",
    "# temp4 = mod_data['subject02']['CSP'][band]['S_tongue']['eigval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04179109, 1.00450402, 1.00331374, 1.00647179, 1.00016541,\n",
       "       0.99888653, 1.00280811, 1.00055237, 1.00208263, 0.99585887,\n",
       "       0.99144243, 0.99665075, 0.9944434 , 0.98998461, 0.99370781,\n",
       "       1.00025226, 0.98977485, 0.9900802 , 0.98506796, 0.99169418,\n",
       "       1.00027066, 1.02019633])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp1 + temp2 + temp3 + temp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Filter (W)\n",
    "Will compute the spatial filter of each subject of each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_filter(B, P):\n",
    "    '''\n",
    "    Will compute projection matrix using the following equation:\n",
    "    W = B' @ P\n",
    "    \n",
    "    INPUT:\n",
    "    B: the eigenvector either left or right class, choose one, size N x N, N is number of electrodes\n",
    "    P: white matrix in size of N x N \n",
    "    \n",
    "    OUTPUT:\n",
    "    W spatial filter to filter EEG\n",
    "    '''\n",
    "    \n",
    "    return (B.T@P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all subject\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        temp_eigvec = mod_data[subj]['CSP'][band]['S_left']['eigvec']\n",
    "        temp_P = mod_data[subj]['CSP'][band]['whitening']['P']\n",
    "\n",
    "        mod_data[subj]['CSP'][band]['W'] = spatial_filter(temp_eigvec, temp_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = mod_data['subject01']['CSP'][band]['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.863146</td>\n",
       "      <td>-2.669347</td>\n",
       "      <td>-1.571843</td>\n",
       "      <td>5.694696</td>\n",
       "      <td>-0.970460</td>\n",
       "      <td>-3.947820</td>\n",
       "      <td>1.513356</td>\n",
       "      <td>-2.630050</td>\n",
       "      <td>-2.284951</td>\n",
       "      <td>4.247328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207029</td>\n",
       "      <td>2.381690</td>\n",
       "      <td>2.278550</td>\n",
       "      <td>-4.750881</td>\n",
       "      <td>-4.476155</td>\n",
       "      <td>-0.803608</td>\n",
       "      <td>-3.557998</td>\n",
       "      <td>7.304860</td>\n",
       "      <td>3.371680</td>\n",
       "      <td>-2.932640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.658305</td>\n",
       "      <td>-1.251084</td>\n",
       "      <td>0.081942</td>\n",
       "      <td>1.119429</td>\n",
       "      <td>-5.523329</td>\n",
       "      <td>3.994098</td>\n",
       "      <td>-1.219727</td>\n",
       "      <td>5.992774</td>\n",
       "      <td>2.410228</td>\n",
       "      <td>-3.186295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302147</td>\n",
       "      <td>-2.525475</td>\n",
       "      <td>-5.839788</td>\n",
       "      <td>-2.241687</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>-2.887461</td>\n",
       "      <td>3.675415</td>\n",
       "      <td>-5.043456</td>\n",
       "      <td>11.604403</td>\n",
       "      <td>-2.798270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.823568</td>\n",
       "      <td>-3.477116</td>\n",
       "      <td>0.346471</td>\n",
       "      <td>1.894111</td>\n",
       "      <td>-8.235573</td>\n",
       "      <td>1.173124</td>\n",
       "      <td>1.320164</td>\n",
       "      <td>6.367581</td>\n",
       "      <td>-4.174698</td>\n",
       "      <td>-0.087842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700528</td>\n",
       "      <td>-6.900167</td>\n",
       "      <td>3.205656</td>\n",
       "      <td>2.930968</td>\n",
       "      <td>-7.986625</td>\n",
       "      <td>0.238110</td>\n",
       "      <td>-0.449117</td>\n",
       "      <td>-0.110425</td>\n",
       "      <td>-0.194263</td>\n",
       "      <td>1.727369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.551897</td>\n",
       "      <td>5.901982</td>\n",
       "      <td>-7.563650</td>\n",
       "      <td>7.398791</td>\n",
       "      <td>-7.093703</td>\n",
       "      <td>2.852894</td>\n",
       "      <td>0.190009</td>\n",
       "      <td>-7.727877</td>\n",
       "      <td>7.787638</td>\n",
       "      <td>-8.207630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339183</td>\n",
       "      <td>2.883259</td>\n",
       "      <td>2.300482</td>\n",
       "      <td>0.839851</td>\n",
       "      <td>2.274352</td>\n",
       "      <td>2.314531</td>\n",
       "      <td>-6.207591</td>\n",
       "      <td>1.037028</td>\n",
       "      <td>-6.397165</td>\n",
       "      <td>3.807562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.637541</td>\n",
       "      <td>1.138712</td>\n",
       "      <td>4.758579</td>\n",
       "      <td>-2.658644</td>\n",
       "      <td>-3.483186</td>\n",
       "      <td>0.963069</td>\n",
       "      <td>-1.665020</td>\n",
       "      <td>0.870338</td>\n",
       "      <td>-2.556526</td>\n",
       "      <td>-0.663024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350288</td>\n",
       "      <td>0.363479</td>\n",
       "      <td>2.253419</td>\n",
       "      <td>7.834621</td>\n",
       "      <td>-4.750676</td>\n",
       "      <td>3.036337</td>\n",
       "      <td>-4.652031</td>\n",
       "      <td>-5.231747</td>\n",
       "      <td>-2.385268</td>\n",
       "      <td>5.799214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.863146 -2.669347 -1.571843  5.694696 -0.970460 -3.947820  1.513356   \n",
       "1 -1.658305 -1.251084  0.081942  1.119429 -5.523329  3.994098 -1.219727   \n",
       "2  3.823568 -3.477116  0.346471  1.894111 -8.235573  1.173124  1.320164   \n",
       "3 -0.551897  5.901982 -7.563650  7.398791 -7.093703  2.852894  0.190009   \n",
       "4 -1.637541  1.138712  4.758579 -2.658644 -3.483186  0.963069 -1.665020   \n",
       "\n",
       "         7         8         9   ...        12        13        14        15  \\\n",
       "0 -2.630050 -2.284951  4.247328  ...  0.207029  2.381690  2.278550 -4.750881   \n",
       "1  5.992774  2.410228 -3.186295  ... -0.302147 -2.525475 -5.839788 -2.241687   \n",
       "2  6.367581 -4.174698 -0.087842  ...  1.700528 -6.900167  3.205656  2.930968   \n",
       "3 -7.727877  7.787638 -8.207630  ... -0.339183  2.883259  2.300482  0.839851   \n",
       "4  0.870338 -2.556526 -0.663024  ...  0.350288  0.363479  2.253419  7.834621   \n",
       "\n",
       "         16        17        18        19         20        21  \n",
       "0 -4.476155 -0.803608 -3.557998  7.304860   3.371680 -2.932640  \n",
       "1  0.027181 -2.887461  3.675415 -5.043456  11.604403 -2.798270  \n",
       "2 -7.986625  0.238110 -0.449117 -0.110425  -0.194263  1.727369  \n",
       "3  2.274352  2.314531 -6.207591  1.037028  -6.397165  3.807562  \n",
       "4 -4.750676  3.036337 -4.652031 -5.231747  -2.385268  5.799214  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(temp).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vector Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new keys for training and test feature vector\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    mod_data[subj]['train'] = {}\n",
    "    mod_data[subj]['test'] = {}\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        mod_data[subj]['train'][band] = {}\n",
    "        mod_data[subj]['test'][band] = {}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select number of filter\n",
    "m = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Z(W, E, m):\n",
    "    '''\n",
    "    Will compute the Z\n",
    "    Z = W @ E, \n",
    "    \n",
    "    E is in the shape of N x M, N is number of electrodes, M is sample\n",
    "    In application, E has nth trial, so there will be n numbers of Z\n",
    "    \n",
    "    Z, in each trial will have dimension of m x M, \n",
    "    where m is the first and last m rows of W, corresponds to smallest and largest eigenvalues\n",
    "    '''\n",
    "    Z = []\n",
    "    \n",
    "    W = np.delete(W, np.s_[m:-m:], 0)\n",
    "    \n",
    "    for i in range(E.shape[0]):\n",
    "        Z.append(W @ E[i])\n",
    "    \n",
    "    return np.array(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_vector(Z):\n",
    "    '''\n",
    "    Will compute the feature vector of Z matrix\n",
    "    \n",
    "    INPUT:\n",
    "    Z : projected EEG shape of T x N x S\n",
    "    \n",
    "    OUTPUT:\n",
    "    feat : feature vector shape of T x m\n",
    "    \n",
    "    T = trial\n",
    "    N = channel\n",
    "    S = sample\n",
    "    m = number of filter\n",
    "    '''\n",
    "    \n",
    "    feat = []\n",
    "    \n",
    "    for i in range(Z.shape[0]):\n",
    "        var = np.var(Z[i], ddof=1, axis=1)\n",
    "        varsum = np.sum(var)\n",
    "        \n",
    "        feat.append(np.log10(var/varsum))\n",
    "        \n",
    "    return np.array(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cov_left', 'cov_right', 'cov_feet', 'cov_tongue', 'cov_comp', 'whitening', 'S_left', 'S_right', 'S_feet', 'S_tongue', 'W'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mod_data['subject01']['CSP']['04_08'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_path', 'EEG_left', 'EEG_right', 'EEG_feet', 'EEG_tongue'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mod_data['subject01']['EEG_filtered'][band].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all subjects\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        temp_W = mod_data[subj]['CSP'][band]['W']\n",
    "        temp_EEG_left = mod_data[subj]['EEG_filtered'][band]['EEG_left']\n",
    "        temp_EEG_right = mod_data[subj]['EEG_filtered'][band]['EEG_right']\n",
    "        temp_EEG_feet = mod_data[subj]['EEG_filtered'][band]['EEG_feet'] # step 1 addition\n",
    "        temp_EEG_tongue = mod_data[subj]['EEG_filtered'][band]['EEG_tongue'] # step 1 addition\n",
    "\n",
    "        # LEFT\n",
    "        mod_data[subj]['train'][band]['Z_left'] = compute_Z(temp_W, temp_EEG_left, m)\n",
    "        mod_data[subj]['train'][band]['feat_left'] = feat_vector(mod_data[subj]['train'][band]['Z_left'])\n",
    "\n",
    "        left_label = np.zeros([len(mod_data[subj]['train'][band]['feat_left']), 1])\n",
    "        \n",
    "        # RIGHT\n",
    "        mod_data[subj]['train'][band]['Z_right'] = compute_Z(temp_W, temp_EEG_right, m)\n",
    "        mod_data[subj]['train'][band]['feat_right'] = feat_vector(mod_data[subj]['train'][band]['Z_right'])\n",
    "        \n",
    "        right_label = np.ones([len(mod_data[subj]['train'][band]['feat_right']), 1])\n",
    "\n",
    "        # Step 1 modification\n",
    "\n",
    "        # FEET\n",
    "        mod_data[subj]['train'][band]['Z_feet'] = compute_Z(temp_W, temp_EEG_feet, m) # step 1 modification\n",
    "        mod_data[subj]['train'][band]['feat_feet'] = feat_vector(mod_data[subj]['train'][band]['Z_feet']) # step 1 modification\n",
    "\n",
    "        feet_label = np.zeros([len(mod_data[subj]['train'][band]['feat_feet']), 1]) # step 1 modification\n",
    "        \n",
    "        # TONGUE\n",
    "        mod_data[subj]['train'][band]['Z_tongue'] = compute_Z(temp_W, temp_EEG_tongue, m) # step 1 modification\n",
    "        mod_data[subj]['train'][band]['feat_tongue'] = feat_vector(mod_data[subj]['train'][band]['Z_tongue']) # step 1 modification\n",
    "        \n",
    "        tongue_label = np.ones([len(mod_data[subj]['train'][band]['feat_tongue']), 1]) # step 1 modification\n",
    "        \n",
    "        left  = np.c_[mod_data[subj]['train'][band]['feat_left'], left_label]\n",
    "        right  = np.c_[mod_data[subj]['train'][band]['feat_right'], right_label] \n",
    "        feet  = np.c_[mod_data[subj]['train'][band]['feat_feet'], feet_label] # step 1 modification\n",
    "        tongue  = np.c_[mod_data[subj]['train'][band]['feat_tongue'], tongue_label] # step 1 modification \n",
    "        \n",
    "        mod_data[subj]['train'][band]['feat_train'] = np.vstack([left, right, feet, tongue]) # step 1 modification\n",
    "        \n",
    "        np.random.shuffle(mod_data[subj]['train'][band]['feat_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[subject01 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject01 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject01 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject01 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject01 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject01 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject01 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject01 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject01 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject02 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject02 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject02 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject02 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject02 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject02 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject02 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject02 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject02 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject03 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject03 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject03 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject03 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject03 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject03 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject03 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject03 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject03 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject04 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject04 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject04 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject04 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject04 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject04 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject04 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject04 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject04 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject05 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject05 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject05 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject05 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject05 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject05 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject05 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject05 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject05 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject06 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject06 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject06 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject06 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject06 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject06 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject06 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject06 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject06 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject07 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject07 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject07 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject07 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject07 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject07 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject07 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject07 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject07 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject08 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject08 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject08 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject08 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject08 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject08 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject08 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject08 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject08 - 36_40] Extracted features shape: (288, 4)\n",
      "[subject09 - 04_08] Extracted features shape: (288, 4)\n",
      "[subject09 - 08_12] Extracted features shape: (288, 4)\n",
      "[subject09 - 12_16] Extracted features shape: (288, 4)\n",
      "[subject09 - 16_20] Extracted features shape: (288, 4)\n",
      "[subject09 - 20_24] Extracted features shape: (288, 4)\n",
      "[subject09 - 24_28] Extracted features shape: (288, 4)\n",
      "[subject09 - 28_32] Extracted features shape: (288, 4)\n",
      "[subject09 - 32_36] Extracted features shape: (288, 4)\n",
      "[subject09 - 36_40] Extracted features shape: (288, 4)\n"
     ]
    }
   ],
   "source": [
    "# # Apply trained CSP filters W to evaluation EEG and extract features\n",
    "\n",
    "# for i in range(1, ns):\n",
    "#     subj = subject_counter(i)\n",
    "    \n",
    "#     for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "#         temp_W = mod_data[subj]['CSP'][band]['W']  # CSP filters learned from training data\n",
    "#         print(f\"[DEBUG][CSP Test] Subject: {subj}, Band: {band}\")\n",
    "#         print(\"  EEG_left shape:\", temp_EEG_left.shape)\n",
    "#         print(\"  EEG_right shape:\", temp_EEG_right.shape)\n",
    "#         print(\"  EEG_feet shape:\", temp_EEG_feet.shape)\n",
    "#         print(\"  EEG_tongue shape:\", temp_EEG_tongue.shape)\n",
    "\n",
    "#         temp_EEG_left = mod_eval_data[subj]['EEG_filtered'][band]['EEG_left']\n",
    "#         temp_EEG_right = mod_eval_data[subj]['EEG_filtered'][band]['EEG_right']\n",
    "#         temp_EEG_feet = mod_eval_data[subj]['EEG_filtered'][band]['EEG_feet']  # step 1 modification\n",
    "#         temp_EEG_tongue = mod_eval_data[subj]['EEG_filtered'][band]['EEG_tongue']  # step 1 modification\n",
    "       \n",
    "        \n",
    "#         Z_left = compute_Z(temp_W, temp_EEG_left, m)\n",
    "#         print(\"  Z_left shape:\", Z_left.shape)\n",
    "#         feat_left = feat_vector(Z_left)\n",
    "#         print(\"  feat_left shape:\", feat_left.shape)\n",
    "\n",
    "#         Z_right = compute_Z(temp_W, temp_EEG_right, m)\n",
    "#         print(\"  Z_right shape:\", Z_right.shape)\n",
    "#         feat_right = feat_vector(Z_right)\n",
    "#         print(\"  feat_right shape:\", feat_right.shape)\n",
    "\n",
    "#         Z_feet = compute_Z(temp_W, temp_EEG_feet, m)\n",
    "#         print(\"  Z_feet shape:\", Z_feet.shape)\n",
    "#         feat_feet = feat_vector(Z_feet)\n",
    "#         print(\"  feat_feet shape:\", feat_feet.shape)\n",
    "\n",
    "#         Z_tongue = compute_Z(temp_W, temp_EEG_tongue, m)\n",
    "#         print(\"  Z_tongue shape:\", Z_tongue.shape)\n",
    "#         feat_tongue = feat_vector(Z_tongue)\n",
    "#         print(\"  feat_tongue shape:\", feat_tongue.shape)\n",
    "        \n",
    "#         # Init dictionary to store features\n",
    "#         mod_eval_data[subj]['test'] = mod_eval_data[subj].get('test', {})\n",
    "#         mod_eval_data[subj]['test'][band] = {}\n",
    "\n",
    "#         # LEFT\n",
    "#         mod_eval_data[subj]['test'][band]['Z_left'] = compute_Z(temp_W, temp_EEG_left, m)\n",
    "#         mod_eval_data[subj]['test'][band]['feat_left'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_left'])\n",
    "#         left_label = np.zeros([len(mod_eval_data[subj]['test'][band]['feat_left']), 1])  # class 0\n",
    "        \n",
    "#         # RIGHT\n",
    "#         mod_eval_data[subj]['test'][band]['Z_right'] = compute_Z(temp_W, temp_EEG_right, m)\n",
    "#         mod_eval_data[subj]['test'][band]['feat_right'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_right'])\n",
    "#         right_label = np.ones([len(mod_eval_data[subj]['test'][band]['feat_right']), 1])  # class 1\n",
    "\n",
    "#         # FEET (step 1 modification)\n",
    "#         mod_eval_data[subj]['test'][band]['Z_feet'] = compute_Z(temp_W, temp_EEG_feet, m)\n",
    "#         mod_eval_data[subj]['test'][band]['feat_feet'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_feet'])\n",
    "#         feet_label = np.full([len(mod_eval_data[subj]['test'][band]['feat_feet']), 1], 2)  # class 2\n",
    "\n",
    "#         # TONGUE (step 1 modification)\n",
    "#         mod_eval_data[subj]['test'][band]['Z_tongue'] = compute_Z(temp_W, temp_EEG_tongue, m)\n",
    "#         mod_eval_data[subj]['test'][band]['feat_tongue'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_tongue'])\n",
    "#         tongue_label = np.full([len(mod_eval_data[subj]['test'][band]['feat_tongue']), 1], 3)  # class 3\n",
    "\n",
    "#         # Merge all features + labels\n",
    "#         left   = np.c_[mod_eval_data[subj]['test'][band]['feat_left'], left_label]\n",
    "#         right  = np.c_[mod_eval_data[subj]['test'][band]['feat_right'], right_label]\n",
    "#         feet   = np.c_[mod_eval_data[subj]['test'][band]['feat_feet'], feet_label]\n",
    "#         tongue = np.c_[mod_eval_data[subj]['test'][band]['feat_tongue'], tongue_label]\n",
    "\n",
    "#         mod_eval_data[subj]['test'][band]['feat_test'] = np.vstack([left, right, feet, tongue])\n",
    "#         np.random.shuffle(mod_eval_data[subj]['test'][band]['feat_test'])  # Shuffle for evaluation fairness\n",
    "\n",
    "\n",
    "# ✅ Batch-based CSP feature extraction for evaluation data\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "\n",
    "    for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "        temp_W = mod_data[subj]['CSP'][band]['W']\n",
    "        eval_trials = mod_eval_data[subj]['EEG_filtered'][band]['eval_trials']  # shape: (T, C, S)\n",
    "\n",
    "        Z = compute_Z(temp_W, eval_trials, m)  # output: (T, 2m, S)\n",
    "        features = feat_vector(Z)  # output: (T, 2m)\n",
    "\n",
    "        mod_eval_data[subj]['EEG_filtered'][band]['features'] = features\n",
    "        print(f\"[{subj} - {band}] Extracted features shape: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Train Feature of All Bandwidth\n",
    "Merging all feature of each bandpass horizontally  \n",
    "This will result in an array with shape of T x (9 * 2m) without true label  \n",
    "where m is the number of filter, and T is number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mod_data['subject01']['train']['04_08']['feat_left'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Iterate over all subjects\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    feat_left_all = []\n",
    "    feat_right_all = []\n",
    "    feat_feet_all = [] # step 1 addition\n",
    "    feat_tongue_all = [] # step 1 addition\n",
    "    \n",
    "    for band in mod_data[subj]['EEG_filtered'].keys():\n",
    "        # Access LEFT each band\n",
    "        feat_left = mod_data[subj]['train'][band]['feat_left']\n",
    "\n",
    "        feat_left_all.append(feat_left)\n",
    "        \n",
    "        # Access RIGHT each band\n",
    "        feat_right = mod_data[subj]['train'][band]['feat_right']\n",
    "\n",
    "        feat_right_all.append(feat_right)      \n",
    "\n",
    "        # Step 1 additions:\n",
    "        # Access FEET each band\n",
    "        feat_feet = mod_data[subj]['train'][band]['feat_feet'] # step 1 modification\n",
    "\n",
    "        feat_feet_all.append(feat_feet) # step 1 modification\n",
    "        \n",
    "        # Access TONGUE each band\n",
    "        feat_tongue = mod_data[subj]['train'][band]['feat_tongue'] # step 1 modification\n",
    "\n",
    "        feat_tongue_all.append(feat_tongue) # step 1 modification\n",
    "        \n",
    "    # MERGING (Need to find more efficient method)\n",
    "    # LEFT\n",
    "    merge_left = np.zeros(feat_left_all[0].shape)\n",
    "\n",
    "    for i in feat_left_all:\n",
    "        merge_left = np.concatenate([merge_left, i], axis=1)\n",
    "    \n",
    "    # Delete initial zeros\n",
    "    merge_left = np.delete(merge_left, np.s_[:2*m], axis=1)\n",
    "    \n",
    "    # RIGHT\n",
    "    merge_right = np.zeros(feat_right_all[0].shape)\n",
    "\n",
    "    for i in feat_right_all:\n",
    "        merge_right = np.concatenate([merge_right, i], axis=1)\n",
    "    \n",
    "    # Delete initial zeros\n",
    "    merge_right = np.delete(merge_right, np.s_[:2*m], axis=1)\n",
    "\n",
    "    # STEP 1 ADDITION:\n",
    "    # FEET\n",
    "    merge_feet = np.zeros(feat_feet_all[0].shape) # step 1 addition\n",
    "\n",
    "    for i in feat_feet_all:\n",
    "        merge_feet = np.concatenate([merge_feet, i], axis=1) # step 1 addition\n",
    "    \n",
    "    # Delete initial zeros\n",
    "    merge_feet = np.delete(merge_feet, np.s_[:2*m], axis=1) # step 1 addition\n",
    "    \n",
    "    # TONGUE\n",
    "    merge_tongue = np.zeros(feat_tongue_all[0].shape) # step 1 addition\n",
    "\n",
    "    for i in feat_tongue_all:\n",
    "        merge_tongue = np.concatenate([merge_tongue, i], axis=1) # step 1 addition\n",
    "    \n",
    "    # Delete initial zeros\n",
    "    merge_tongue = np.delete(merge_tongue, np.s_[:2*m], axis=1) # step 1 addition\n",
    "    \n",
    "    # TRUE LABEL\n",
    "    true_left = np.zeros([merge_left.shape[0], 1])\n",
    "    true_right = np.ones([merge_right.shape[0], 1])\n",
    "    true_feet = np.full([merge_feet.shape[0], 1], 2) # step 1 addition\n",
    "    true_tongue = np.full([merge_tongue.shape[0], 1], 3) # step 1 addition\n",
    "    \n",
    "    # FEATURE + TRUE LABEL\n",
    "    left = np.hstack([merge_left, true_left])\n",
    "    right = np.hstack([merge_right, true_right])    \n",
    "    feet = np.hstack([merge_feet, true_feet]) # step 1 addition\n",
    "    tongue = np.hstack([merge_tongue, true_tongue]) # step 1 addition    \n",
    "    \n",
    "    # MERGE LEFT AND RIGHT \n",
    "    train_feat = np.vstack([left, right, feet, tongue]) # step 1 addition\n",
    "    \n",
    "    np.random.shuffle(train_feat)\n",
    "    \n",
    "    mod_data[subj]['train']['all_band'] = train_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Subject: subject01\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject02\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject03\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject04\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject05\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject06\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject07\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject08\n",
      "  Final all_band shape: (288, 36)\n",
      "[DEBUG] Subject: subject09\n",
      "  Final all_band shape: (288, 36)\n"
     ]
    }
   ],
   "source": [
    "# # Iterate over all subjects to merge evaluation features across bands\n",
    "# for i in range(1, ns):\n",
    "#     subj = subject_counter(i)\n",
    "    \n",
    "#     feat_left_all_eval = []\n",
    "#     feat_right_all_eval = []\n",
    "#     feat_feet_all_eval = []  # step 1 addition\n",
    "#     feat_tongue_all_eval = []  # step 1 addition\n",
    "    \n",
    "#     for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "#         # Access LEFT feature for each band\n",
    "#         feat_left_eval = mod_eval_data[subj]['test'][band]['feat_left']\n",
    "#         feat_left_all_eval.append(feat_left_eval)\n",
    "        \n",
    "#         # Access RIGHT feature for each band\n",
    "#         feat_right_eval = mod_eval_data[subj]['test'][band]['feat_right']\n",
    "#         feat_right_all_eval.append(feat_right_eval)\n",
    "        \n",
    "#         # Access FEET feature for each band\n",
    "#         feat_feet_eval = mod_eval_data[subj]['test'][band]['feat_feet']\n",
    "#         feat_feet_all_eval.append(feat_feet_eval)\n",
    "        \n",
    "#         # Access TONGUE feature for each band\n",
    "#         feat_tongue_eval = mod_eval_data[subj]['test'][band]['feat_tongue']\n",
    "#         feat_tongue_all_eval.append(feat_tongue_eval)\n",
    "    \n",
    "#     # Correct stacking\n",
    "#     merge_left_eval = np.vstack(feat_left_all_eval)\n",
    "#     merge_right_eval = np.vstack(feat_right_all_eval)\n",
    "#     merge_feet_eval = np.vstack(feat_feet_all_eval)\n",
    "#     merge_tongue_eval = np.vstack(feat_tongue_all_eval)\n",
    "    \n",
    "#     # TRUE LABELS\n",
    "#     true_left_eval = np.zeros([merge_left_eval.shape[0], 1])\n",
    "#     true_right_eval = np.ones([merge_right_eval.shape[0], 1])\n",
    "#     true_feet_eval = np.full([merge_feet_eval.shape[0], 1], 2)\n",
    "#     true_tongue_eval = np.full([merge_tongue_eval.shape[0], 1], 3)\n",
    "    \n",
    "#     # FEATURE + TRUE LABEL\n",
    "#     left_eval = np.hstack([merge_left_eval, true_left_eval])\n",
    "#     right_eval = np.hstack([merge_right_eval, true_right_eval])\n",
    "#     feet_eval = np.hstack([merge_feet_eval, true_feet_eval])\n",
    "#     tongue_eval = np.hstack([merge_tongue_eval, true_tongue_eval])\n",
    "    \n",
    "#     # MERGE ALL CLASSES\n",
    "#     test_feat_eval = np.vstack([left_eval, right_eval, feet_eval, tongue_eval])\n",
    "    \n",
    "#     np.random.shuffle(test_feat_eval)\n",
    "    \n",
    "#     # Save merged evaluation features\n",
    "#     mod_eval_data[subj]['test']['all_band'] = test_feat_eval\n",
    "#     print(f\"[DEBUG] Subject: {subj}\")\n",
    "#     print(\"  Final all_band shape:\", test_feat_eval.shape)\n",
    "\n",
    "#     for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "#         for cls in ['feat_left', 'feat_right', 'feat_feet', 'feat_tongue']:\n",
    "#             shape = mod_eval_data[subj]['test'][band][cls].shape\n",
    "#             print(f\"  Band: {band}, Class: {cls}, Shape: {shape}\")\n",
    "\n",
    "\n",
    "# ✅ Merge evaluation features across bands (read from 'EEG_filtered')\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "\n",
    "    feat_all_bands = []\n",
    "\n",
    "    for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "        band_feats = mod_eval_data[subj]['EEG_filtered'][band]['features']  # (n_trials, n_features)\n",
    "        feat_all_bands.append(band_feats)\n",
    "\n",
    "    # Concatenate across feature dimension\n",
    "    merged_eval_feats = np.concatenate(feat_all_bands, axis=1)\n",
    "\n",
    "    # Store for later steps (e.g., MI selection, classification)\n",
    "    mod_eval_data[subj]['test'] = {}  # create the 'test' key now\n",
    "    mod_eval_data[subj]['test']['all_band'] = merged_eval_feats\n",
    "\n",
    "    print(f\"[DEBUG] Subject: {subj}\")\n",
    "    print(\"  Final all_band shape:\", merged_eval_feats.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# assert (mod_data['subject01']['train']['all_band'].shape == (116, 9*2*m + 1)) # old correct dimensions, pre-step 1\n",
    "assert (mod_data['subject01']['train']['all_band'].shape == (288, 9*2*m + 1)) # new correct dimensions with double the classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Based Information (MI) to Select Most Informative Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Subject: subject01\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject02\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject03\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject04\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject05\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject06\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject07\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject08\n",
      "  X_train: (288, 36), selected: (288, 4)\n",
      "\n",
      "[TRAIN] Subject: subject09\n",
      "  X_train: (288, 36), selected: (288, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "\n",
    "    print(f\"\\n[TRAIN] Subject: {subj}\")\n",
    "\n",
    "    all_data = mod_data[subj]['train']['all_band']  # Full training feature + label matrix\n",
    "    X_train = all_data[:, :-1]  # Features\n",
    "    y_train = all_data[:, -1]   # Labels\n",
    "\n",
    "    # Mutual information feature selection\n",
    "    selector = SelectKBest(mutual_info_classif, k=4)\n",
    "    selector.fit(X_train, y_train)\n",
    "    X_sel = selector.transform(X_train)\n",
    "\n",
    "    # Save result\n",
    "    mod_data[subj]['mutual'] = {\n",
    "        'X': X_sel,\n",
    "        'y': y_train,\n",
    "        'selector': selector\n",
    "    }\n",
    "\n",
    "    print(f\"  X_train: {X_train.shape}, selected: {X_sel.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vector Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Seed to fix randomization\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # STEP 2 ADDITIONS: test data is grabbed from mod_eval_data as opposed to mod_data['test'], since\n",
    "# # that held 20% of the split TRAIN data previously, when the test data is now 100% of the eval data (from A0XE.npz files)\n",
    "\n",
    "\n",
    "# # Iterate over all subjects\n",
    "# for i in range(1, ns):\n",
    "#     subj = subject_counter(i)\n",
    "    \n",
    "#     for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "#         temp_W = mod_data[subj]['CSP'][band]['W']  # Use CSP filters trained from mod_data\n",
    "        \n",
    "#         # Load evaluation EEGs (already segmented)\n",
    "#         temp_EEG_left = mod_eval_data[subj]['EEG_filtered'][band]['EEG_left']\n",
    "#         temp_EEG_right = mod_eval_data[subj]['EEG_filtered'][band]['EEG_right']\n",
    "#         temp_EEG_feet = mod_eval_data[subj]['EEG_filtered'][band]['EEG_feet']  # step 1 addition\n",
    "#         temp_EEG_tongue = mod_eval_data[subj]['EEG_filtered'][band]['EEG_tongue']  # step 1 addition\n",
    "\n",
    "#         mod_eval_data[subj]['test'][band] = {}  # Initialize dictionary for test features\n",
    "\n",
    "#         # LEFT\n",
    "#         mod_eval_data[subj]['test'][band]['Z_left'] = compute_Z(temp_W, temp_EEG_left, m)\n",
    "#         mod_eval_data[subj]['test'][band]['feat_left'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_left'])\n",
    "#         left_label = np.zeros([len(mod_eval_data[subj]['test'][band]['feat_left']), 1])\n",
    "\n",
    "#         # RIGHT\n",
    "#         mod_eval_data[subj]['test'][band]['Z_right'] = compute_Z(temp_W, temp_EEG_right, m)\n",
    "#         mod_eval_data[subj]['test'][band]['feat_right'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_right'])\n",
    "#         right_label = np.ones([len(mod_eval_data[subj]['test'][band]['feat_right']), 1])\n",
    "\n",
    "#         # Step 1 additions:\n",
    "#         # FEET\n",
    "#         mod_eval_data[subj]['test'][band]['Z_feet'] = compute_Z(temp_W, temp_EEG_feet, m)  # step 1 addition\n",
    "#         mod_eval_data[subj]['test'][band]['feat_feet'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_feet'])  # step 1 addition\n",
    "#         feet_label = np.full([len(mod_eval_data[subj]['test'][band]['feat_feet']), 1], 2)  # step 1 addition (label 2 for feet)\n",
    "\n",
    "#         # TONGUE\n",
    "#         mod_eval_data[subj]['test'][band]['Z_tongue'] = compute_Z(temp_W, temp_EEG_tongue, m)  # step 1 addition\n",
    "#         mod_eval_data[subj]['test'][band]['feat_tongue'] = feat_vector(mod_eval_data[subj]['test'][band]['Z_tongue'])  # step 1 addition_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging TEST Feature of All Bandwidth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over all subjects to merge evaluation features across bands\n",
    "# for i in range(1, ns):\n",
    "#     subj = subject_counter(i)\n",
    "    \n",
    "#     feat_left_all_eval = []\n",
    "#     feat_right_all_eval = []\n",
    "#     feat_feet_all_eval = []  # step 1 addition\n",
    "#     feat_tongue_all_eval = []  # step 1 addition\n",
    "    \n",
    "#     for band in mod_eval_data[subj]['EEG_filtered'].keys():\n",
    "#         # Access LEFT each band\n",
    "#         feat_left_eval = mod_eval_data[subj]['test'][band]['feat_left']\n",
    "#         feat_left_all_eval.append(feat_left_eval)\n",
    "        \n",
    "#         # Access RIGHT each band\n",
    "#         feat_right_eval = mod_eval_data[subj]['test'][band]['feat_right']\n",
    "#         feat_right_all_eval.append(feat_right_eval)\n",
    "        \n",
    "#         # Step 1 additions\n",
    "#         # Access FEET each band\n",
    "#         feat_feet_eval = mod_eval_data[subj]['test'][band]['feat_feet']  # step 1 addition\n",
    "#         feat_feet_all_eval.append(feat_feet_eval)  # step 1 addition\n",
    "        \n",
    "#         # Access TONGUE each band\n",
    "#         feat_tongue_eval = mod_eval_data[subj]['test'][band]['feat_tongue']  # step 1 addition\n",
    "#         feat_tongue_all_eval.append(feat_tongue_eval)  # step 1 addition\n",
    "    \n",
    "#     # MERGING (vstack each class)\n",
    "#     # LEFT\n",
    "#     merge_left_eval = np.vstack(feat_left_all_eval)\n",
    "    \n",
    "#     # RIGHT\n",
    "#     merge_right_eval = np.vstack(feat_right_all_eval)\n",
    "\n",
    "#     # FEET (step 1 addition)\n",
    "#     merge_feet_eval = np.vstack(feat_feet_all_eval)  # step 1 addition\n",
    "\n",
    "#     # TONGUE (step 1 addition)\n",
    "#     merge_tongue_eval = np.vstack(feat_tongue_all_eval)  # step 1 addition\n",
    "    \n",
    "#     # TRUE LABELS\n",
    "#     true_left_eval = np.zeros([merge_left_eval.shape[0], 1])\n",
    "#     true_right_eval = np.ones([merge_right_eval.shape[0], 1])\n",
    "#     true_feet_eval = np.full([merge_feet_eval.shape[0], 1], 2)  # step 1 addition\n",
    "#     true_tongue_eval = np.full([merge_tongue_eval.shape[0], 1], 3)  # step 1 addition\n",
    "    \n",
    "#     # FEATURE + TRUE LABEL\n",
    "#     left_eval = np.hstack([merge_left_eval, true_left_eval])\n",
    "#     right_eval = np.hstack([merge_right_eval, true_right_eval])\n",
    "#     feet_eval = np.hstack([merge_feet_eval, true_feet_eval])  # step 1 addition\n",
    "#     tongue_eval = np.hstack([merge_tongue_eval, true_tongue_eval])  # step 1 addition\n",
    "    \n",
    "#     # MERGE LEFT AND RIGHT AND FEET AND TONGUE (step 1 addition)\n",
    "#     test_feat_eval = np.vstack([left_eval, right_eval, feet_eval, tongue_eval])  # step 1 addition\n",
    "    \n",
    "#     np.random.shuffle(test_feat_eval)\n",
    "    \n",
    "#     mod_eval_data[subj]['test']['all_band'] = test_feat_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_data['subject01']['test']['all_band'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Based Information (MI) to Select Most Informative Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] Subject: subject01\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject02\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject03\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject04\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject05\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject06\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject07\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject08\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n",
      "[TEST] Subject: subject09\n",
      "X_test shape: (288, 36)\n",
      "Selector expects: 36 features\n"
     ]
    }
   ],
   "source": [
    "# ## Mutual Based Information (MI) to Select Most Informative Band (APPLY ONLY)\n",
    "# for i in range(1, ns):\n",
    "#     subj = subject_counter(i)\n",
    "    \n",
    "#     X_test = mod_eval_data[subj]['test']['all_band'][:, :-1]\n",
    "#     y_test = mod_eval_data[subj]['test']['all_band'][:, -1]\n",
    "    \n",
    "#     selector = mod_data[subj]['train']['mutual']['selector']  # ✅ Load from train\n",
    "\n",
    "#     print(f\"[TEST] Subject: {subj}\")\n",
    "#     print(f\"X_test shape: {X_test.shape}\")\n",
    "#     print(f\"Selector expects: {selector.get_support().shape[0]} features\")\n",
    "\n",
    "#     # Apply selector to test data\n",
    "#     X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "#     # Store selected test features\n",
    "#     mod_eval_data[subj]['test']['mutual'] = {\n",
    "#         'X': X_test_selected,\n",
    "#         'y': y_test\n",
    "#     }\n",
    "\n",
    "## ✅ Apply trained Mutual Information selector to evaluation data (features only)\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    X_test = mod_eval_data[subj]['test']['all_band']  # Already excludes labels now\n",
    "    selector = mod_data[subj]['mutual']['selector']  # Trained selector from training phase\n",
    "\n",
    "    print(f\"[TEST] Subject: {subj}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"Selector expects: {selector.get_support().shape[0]} features\")\n",
    "\n",
    "    # Apply feature selector\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Store selected test features (no labels)\n",
    "    mod_eval_data[subj]['test']['mutual'] = {\n",
    "        'X': X_test_selected\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for subject01\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject02\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject03\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject04\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject05\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject06\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject07\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject08\n",
      "✅ Eval Accuracy: 54.87%\n",
      "Processing for subject09\n",
      "✅ Eval Accuracy: 54.87%\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each subject\n",
    "from sklearn.model_selection import cross_val_score\n",
    "eval_acc = []\n",
    "eval_std = []\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    print('Processing for {}'.format(subj))\n",
    "    X_train = mod_data[subj]['mutual']['X']\n",
    "    y_train = mod_data[subj]['mutual']['y']\n",
    "    # X_test = mod_eval_data[subj]['test']['mutual']['X']\n",
    "    # y_test = mod_eval_data[subj]['test']['mutual']['y']\n",
    "    \n",
    "    model = SVC(kernel='linear', C=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    \n",
    "    eval_acc.append(cross_val_score(model, X_train, y_train, cv=5).mean() * 100)\n",
    "    eval_std.append(cross_val_score(model, X_train, y_train, cv=5).std()*100)\n",
    "    \n",
    "    print(f\"✅ Eval Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary variable to label x axis\n",
    "subject=[]\n",
    "for i in range(1, ns):\n",
    "    subject.append(subject_counter(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Accuracy for all subjects ======\n",
      "Subject01 : 70.49 % +/- 2.14\n",
      "Subject02 : 48.93 % +/- 7.96\n",
      "Subject03 : 57.33 % +/- 6.01\n",
      "Subject04 : 46.16 % +/- 2.75\n",
      "Subject05 : 53.79 % +/- 3.57\n",
      "Subject06 : 42.38 % +/- 4.96\n",
      "Subject07 : 58.34 % +/- 1.79\n",
      "Subject08 : 72.93 % +/- 4.98\n",
      "Subject09 : 54.87 % +/- 3.51\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=80)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "ax.set_title('Accuracy (%)')\n",
    "ax.grid(axis='y', alpha=0.5)\n",
    "ax.bar(np.arange(1, ns), eval_acc, color=\"#ffb152\", yerr=eval_std, capsize=5)\n",
    "ax.set(xticks=np.arange(1, ns), xlabel='Subject', \n",
    "       yticks=np.arange(0, 101, step=10), ylabel='Accuracy',\n",
    "       title='5-fold Train Cross Validation Result')\n",
    "ax.set_axisbelow(True)\n",
    "plt.savefig('5fold_train_result.jpg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print each subject accuracy\n",
    "print(\"====== Accuracy for all subjects ======\")\n",
    "for i in range(ns-1):\n",
    "    print(\"Subject{:02d} : {:.2f} % +/- {:.2f}\".format(i+1, eval_acc[i], eval_std[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result on Test Data\n",
    "Based on initial observation, svc model performed well on train data. Thus we will proceed to use the current model to evaluate on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject01: Loaded 288 test labels.\n",
      "subject02: Loaded 288 test labels.\n",
      "subject03: Loaded 288 test labels.\n",
      "subject04: Loaded 288 test labels.\n",
      "subject05: Loaded 288 test labels.\n",
      "subject06: Loaded 288 test labels.\n",
      "subject07: Loaded 288 test labels.\n",
      "subject08: Loaded 288 test labels.\n",
      "subject09: Loaded 288 test labels.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "\n",
    "label_dir = \"/Users/nathandayie/Downloads/School/Vinjamuri Lab/VinjamuriEEGProject/true_labels\"\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    filename = f\"A{i:02d}E.mat\"\n",
    "    mat_path = os.path.join(label_dir, filename)\n",
    "\n",
    "    label_data = loadmat(mat_path)\n",
    "    true_labels = label_data['classlabel'].flatten()  # shape: (288,)\n",
    "\n",
    "    mod_eval_data[subj]['test']['mutual']['y'] = true_labels\n",
    "    print(f\"{subj}: Loaded {len(true_labels)} test labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject01: Test Accuracy = 20.49%\n",
      "subject02: Test Accuracy = 17.71%\n",
      "subject03: Test Accuracy = 25.00%\n",
      "subject04: Test Accuracy = 18.75%\n",
      "subject05: Test Accuracy = 4.17%\n",
      "subject06: Test Accuracy = 19.44%\n",
      "subject07: Test Accuracy = 25.35%\n",
      "subject08: Test Accuracy = 21.18%\n",
      "subject09: Test Accuracy = 27.78%\n"
     ]
    }
   ],
   "source": [
    "# Blank list to store accuracy values\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "\n",
    "    X_train = mod_data[subj]['mutual']['X']\n",
    "    y_train = mod_data[subj]['mutual']['y']\n",
    "    X_test = mod_eval_data[subj]['test']['mutual']['X']\n",
    "    y_test = mod_eval_data[subj]['test']['mutual']['y']  # ✅ now defined\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    test_score.append(acc)\n",
    "\n",
    "    print(f\"{subj}: Test Accuracy = {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Test Accuracy for all subjects ======\n",
      "Subject01 : 20.49 %\n",
      "Subject02 : 17.71 %\n",
      "Subject03 : 25.00 %\n",
      "Subject04 : 18.75 %\n",
      "Subject05 : 4.17 %\n",
      "Subject06 : 19.44 %\n",
      "Subject07 : 25.35 %\n",
      "Subject08 : 21.18 %\n",
      "Subject09 : 27.78 %\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=80)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "ax.set_title('Accuracy (%)')\n",
    "ax.grid(axis='y', alpha=0.5)\n",
    "ax.bar(np.arange(1, ns), test_score, color=\"#3ebbed\")\n",
    "ax.set(xticks=np.arange(1, ns), xlabel='Subject', \n",
    "       yticks=np.arange(0, 101, step=10), ylabel='Accuracy',\n",
    "       title='5-fold Test Cross Validation Result')\n",
    "ax.set_axisbelow(True)\n",
    "plt.savefig('5fold_test_result.jpg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print each subject accuracy\n",
    "print(\"====== Test Accuracy for all subjects ======\")\n",
    "for i in range(ns-1):\n",
    "    print(\"Subject{:02d} : {:.2f} %\".format(i+1, test_score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
